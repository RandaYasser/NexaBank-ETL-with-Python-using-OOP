2025-05-14 00:26:30,017 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 00:26:30,019 - __main__ - INFO - Pipeline initialized successfully
2025-05-14 00:26:30,020 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-14 00:26:30,020 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-14 00:26:30,625 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\00\credit_cards_billing.parquet
2025-05-14 00:26:30,952 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\00\credit_cards_billing.parquet
2025-05-14 00:26:30,952 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\00\credit_cards_billing.parquet
2025-05-14 00:26:30,955 - src.pipeline.main_pipeline - INFO - Successfully processed credit_cards_billing.csv
2025-05-14 00:26:30,965 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-14 00:26:31,424 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\customer_profiles.parquet
2025-05-14 00:26:31,424 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\customer_profiles.parquet
2025-05-14 00:26:31,424 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\customer_profiles.parquet
2025-05-14 00:26:31,688 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\customer_profiles.parquet
2025-05-14 00:26:31,688 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\customer_profiles.parquet
2025-05-14 00:26:31,688 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\customer_profiles.parquet
2025-05-14 00:26:31,688 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\customer_profiles.parquet
2025-05-14 00:26:31,691 - src.pipeline.main_pipeline - INFO - Successfully processed customer_profiles.csv
2025-05-14 00:26:31,697 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-14 00:26:31,716 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\00\loans.parquet
2025-05-14 00:26:31,716 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\00\loans.parquet
2025-05-14 00:26:31,716 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\00\loans.parquet
2025-05-14 00:26:31,716 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\00\loans.parquet
2025-05-14 00:26:31,716 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\00\loans.parquet
2025-05-14 00:26:31,729 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: name 'self' is not defined
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\loans_transformer.py", line 25, in transform
    df['loan_reason'] = Encryptor.encrypt(df['loan_reason'])
  File "d:\ITI\Python\Project\src\utils\encryptor.py", line 25, in encrypt
    encrypted_text = self._caesar_cipher(text, key)
NameError: name 'self' is not defined

2025-05-14 00:26:33,404 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f57ddfbesm17771254f8f.10 - gsmtp')
2025-05-14 00:26:33,405 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-14 00:26:33,466 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\00\support_tickets.parquet
2025-05-14 00:26:33,466 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\00\support_tickets.parquet
2025-05-14 00:26:33,466 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\00\support_tickets.parquet
2025-05-14 00:26:33,466 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\00\support_tickets.parquet
2025-05-14 00:26:33,466 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\00\support_tickets.parquet
2025-05-14 00:26:33,466 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\00\support_tickets.parquet
2025-05-14 00:26:33,507 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\00\support_tickets.parquet
2025-05-14 00:26:33,507 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\00\support_tickets.parquet
2025-05-14 00:26:33,507 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\00\support_tickets.parquet
2025-05-14 00:26:33,507 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\00\support_tickets.parquet
2025-05-14 00:26:33,507 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\00\support_tickets.parquet
2025-05-14 00:26:33,507 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\00\support_tickets.parquet
2025-05-14 00:26:33,507 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\00\support_tickets.parquet
2025-05-14 00:26:33,511 - src.pipeline.main_pipeline - INFO - Successfully processed support_tickets.csv
2025-05-14 00:26:33,513 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-14 00:26:34,013 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\transactions.parquet
2025-05-14 00:26:34,013 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\transactions.parquet
2025-05-14 00:26:34,013 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\transactions.parquet
2025-05-14 00:26:34,013 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\transactions.parquet
2025-05-14 00:26:34,013 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\transactions.parquet
2025-05-14 00:26:34,013 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\transactions.parquet
2025-05-14 00:26:34,013 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\transactions.parquet
2025-05-14 00:26:34,013 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\transactions.parquet
2025-05-14 00:26:34,129 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:26:34,129 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:26:34,129 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:26:34,129 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:26:34,129 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:26:34,129 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:26:34,129 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:26:34,129 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:26:34,129 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:26:34,134 - src.pipeline.main_pipeline - INFO - Successfully processed transactions.json
2025-05-14 00:27:00,633 - __main__ - INFO - Pipeline stopped by user
2025-05-14 00:27:53,776 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 00:27:53,780 - __main__ - INFO - Pipeline initialized successfully
2025-05-14 00:27:53,780 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-14 00:27:53,781 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-14 00:27:54,367 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\00\credit_cards_billing.parquet
2025-05-14 00:27:54,656 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\00\credit_cards_billing.parquet
2025-05-14 00:27:54,656 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\00\credit_cards_billing.parquet
2025-05-14 00:27:54,658 - src.pipeline.main_pipeline - INFO - Successfully processed credit_cards_billing.csv
2025-05-14 00:27:54,672 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-14 00:27:55,099 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\customer_profiles.parquet
2025-05-14 00:27:55,099 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\customer_profiles.parquet
2025-05-14 00:27:55,099 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\customer_profiles.parquet
2025-05-14 00:27:55,370 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\customer_profiles.parquet
2025-05-14 00:27:55,370 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\customer_profiles.parquet
2025-05-14 00:27:55,370 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\customer_profiles.parquet
2025-05-14 00:27:55,370 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\customer_profiles.parquet
2025-05-14 00:27:55,374 - src.pipeline.main_pipeline - INFO - Successfully processed customer_profiles.csv
2025-05-14 00:27:55,382 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-14 00:27:55,398 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\00\loans.parquet
2025-05-14 00:27:55,398 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\00\loans.parquet
2025-05-14 00:27:55,398 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\00\loans.parquet
2025-05-14 00:27:55,398 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\00\loans.parquet
2025-05-14 00:27:55,398 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\00\loans.parquet
2025-05-14 00:27:55,550 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\00\loans.parquet
2025-05-14 00:27:55,550 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\00\loans.parquet
2025-05-14 00:27:55,550 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\00\loans.parquet
2025-05-14 00:27:55,550 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\00\loans.parquet
2025-05-14 00:27:55,550 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\00\loans.parquet
2025-05-14 00:27:55,550 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\00\loans.parquet
2025-05-14 00:27:55,554 - src.pipeline.main_pipeline - INFO - Successfully processed loans.txt
2025-05-14 00:27:55,555 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-14 00:27:55,611 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\00\support_tickets.parquet
2025-05-14 00:27:55,611 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\00\support_tickets.parquet
2025-05-14 00:27:55,611 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\00\support_tickets.parquet
2025-05-14 00:27:55,611 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\00\support_tickets.parquet
2025-05-14 00:27:55,611 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\00\support_tickets.parquet
2025-05-14 00:27:55,611 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\00\support_tickets.parquet
2025-05-14 00:27:55,611 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\00\support_tickets.parquet
2025-05-14 00:27:55,646 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\00\support_tickets.parquet
2025-05-14 00:27:55,646 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\00\support_tickets.parquet
2025-05-14 00:27:55,646 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\00\support_tickets.parquet
2025-05-14 00:27:55,646 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\00\support_tickets.parquet
2025-05-14 00:27:55,646 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\00\support_tickets.parquet
2025-05-14 00:27:55,646 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\00\support_tickets.parquet
2025-05-14 00:27:55,646 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\00\support_tickets.parquet
2025-05-14 00:27:55,646 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\00\support_tickets.parquet
2025-05-14 00:27:55,652 - src.pipeline.main_pipeline - INFO - Successfully processed support_tickets.csv
2025-05-14 00:27:55,654 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-14 00:27:56,067 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,067 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,067 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,067 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,067 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,067 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,067 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,067 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,067 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\00\transactions.parquet
2025-05-14 00:27:56,181 - src.pipeline.main_pipeline - INFO - Successfully processed transactions.json
2025-05-14 00:53:54,180 - __main__ - INFO - Pipeline stopped by user
2025-05-14 00:56:53,897 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 00:56:53,900 - __main__ - ERROR - Pipeline failed: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-05-14 01:00:21,523 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 01:00:21,526 - __main__ - INFO - Pipeline initialized successfully
2025-05-14 01:00:21,526 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-14 01:00:27,427 - __main__ - INFO - Pipeline stopped by user
2025-05-14 01:01:26,582 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 01:01:26,585 - __main__ - INFO - Pipeline initialized successfully
2025-05-14 01:01:26,586 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-14 01:01:26,587 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-14 01:01:27,116 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:01:27,428 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:01:27,428 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:01:27,430 - src.pipeline.main_pipeline - INFO - Successfully processed credit_cards_billing.csv
2025-05-14 01:01:27,441 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-14 01:01:27,825 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:01:27,825 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:01:27,825 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:01:28,105 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:01:28,105 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:01:28,105 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:01:28,105 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:01:28,108 - src.pipeline.main_pipeline - INFO - Successfully processed customer_profiles.csv
2025-05-14 01:01:28,116 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-14 01:01:28,135 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:01:28,135 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:01:28,135 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:01:28,135 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:01:28,135 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:01:28,189 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:01:28,189 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:01:28,189 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:01:28,189 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:01:28,189 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:01:28,189 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:01:28,195 - src.pipeline.main_pipeline - INFO - Successfully processed loans.txt
2025-05-14 01:01:28,197 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-14 01:01:28,252 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:01:28,252 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:01:28,252 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:01:28,252 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:01:28,252 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:01:28,252 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:01:28,252 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:01:28,288 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:01:28,288 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:01:28,288 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:01:28,288 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:01:28,288 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:01:28,288 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:01:28,288 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:01:28,288 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:01:28,295 - src.pipeline.main_pipeline - INFO - Successfully processed support_tickets.csv
2025-05-14 01:01:28,298 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-14 01:01:28,707 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,707 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,707 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,707 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,707 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,707 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,707 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,707 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,707 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,808 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,808 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,808 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,808 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,808 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,808 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,808 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,808 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,808 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,808 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:01:28,816 - src.pipeline.main_pipeline - INFO - Successfully processed transactions.json
2025-05-14 01:03:38,842 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-14 01:03:39,504 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,504 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,504 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,504 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,504 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,504 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,504 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,504 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,504 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,504 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,504 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,836 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,836 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,836 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,836 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,836 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,836 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,836 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,836 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,836 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,836 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,836 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,836 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:03:39,845 - src.pipeline.main_pipeline - INFO - Successfully processed credit_cards_billing.csv
2025-05-14 01:03:39,859 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-14 01:03:40,270 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,270 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,270 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,270 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,270 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,270 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,270 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,270 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,270 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,270 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,270 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,270 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,270 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,555 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,555 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,555 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,555 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,555 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,555 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,555 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,555 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,555 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,555 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,555 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,555 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,555 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,555 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:03:40,562 - src.pipeline.main_pipeline - INFO - Successfully processed customer_profiles.csv
2025-05-14 01:03:40,569 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-14 01:03:40,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,712 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,712 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,712 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,712 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,712 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,712 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,712 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,712 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,712 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,712 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,712 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,712 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,712 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,712 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,712 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,712 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:03:40,731 - src.pipeline.main_pipeline - INFO - Successfully processed loans.txt
2025-05-14 01:03:40,733 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-14 01:03:40,877 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,877 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,877 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,877 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,877 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,877 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,877 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,877 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,877 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,877 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,877 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,877 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,877 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,877 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,877 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,877 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,877 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,965 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,965 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,965 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,965 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,965 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,965 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,965 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,965 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,965 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,965 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,965 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,965 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,965 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,965 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,965 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,965 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,965 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,965 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:03:40,994 - src.pipeline.main_pipeline - INFO - Successfully processed support_tickets.csv
2025-05-14 01:03:40,997 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,565 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,691 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:03:41,704 - src.pipeline.main_pipeline - INFO - Successfully processed transactions.json
2025-05-14 01:03:48,343 - __main__ - INFO - Pipeline stopped by user
2025-05-14 01:04:32,636 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 01:04:32,638 - __main__ - INFO - Pipeline initialized successfully
2025-05-14 01:04:32,639 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-14 01:04:32,640 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-14 01:04:33,275 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:04:33,617 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:04:33,617 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:04:33,678 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-14 01:04:33,678 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-14 01:04:33,685 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.

2025-05-14 01:04:33,688 - src.utils.error_handler - ERROR - Failed to send error notification email: 'ErrorHandler' object has no attribute 'email_config'
2025-05-14 01:04:33,700 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-14 01:04:34,119 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:04:34,119 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:04:34,119 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:04:34,477 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:04:34,477 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:04:34,477 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:04:34,477 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:04:34,537 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:04:34,537 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:04:34,537 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:04:34,537 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:04:34,542 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.

2025-05-14 01:04:34,545 - src.utils.error_handler - ERROR - Failed to send error notification email: 'ErrorHandler' object has no attribute 'email_config'
2025-05-14 01:04:34,555 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-14 01:04:34,572 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:04:34,572 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:04:34,572 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:04:34,572 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:04:34,572 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:04:34,665 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:04:34,665 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:04:34,665 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:04:34,665 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:04:34,665 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:04:34,665 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:04:34,719 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:04:34,719 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:04:34,719 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:04:34,719 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:04:34,719 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:04:34,719 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:04:34,724 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.

2025-05-14 01:04:34,727 - src.utils.error_handler - ERROR - Failed to send error notification email: 'ErrorHandler' object has no attribute 'email_config'
2025-05-14 01:04:34,729 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-14 01:04:34,792 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:04:34,792 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:04:34,792 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:04:34,792 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:04:34,792 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:04:34,792 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:04:34,792 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:04:34,829 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:04:34,829 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:04:34,829 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:04:34,829 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:04:34,829 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:04:34,829 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:04:34,829 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:04:34,829 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:04:34,877 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:04:34,877 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:04:34,877 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:04:34,877 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:04:34,877 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:04:34,877 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:04:34,877 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:04:34,877 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:04:34,885 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.

2025-05-14 01:04:34,888 - src.utils.error_handler - ERROR - Failed to send error notification email: 'ErrorHandler' object has no attribute 'email_config'
2025-05-14 01:04:34,890 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-14 01:04:35,385 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,385 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,385 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,385 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,385 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,385 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,385 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,385 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,385 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,497 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,497 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,497 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,497 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,497 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,497 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,497 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,497 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,497 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,497 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:04:35,557 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:04:35,557 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:04:35,557 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:04:35,557 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:04:35,557 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:04:35,557 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:04:35,557 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:04:35,557 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:04:35,557 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:04:35,557 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:04:35,566 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.

2025-05-14 01:04:35,569 - src.utils.error_handler - ERROR - Failed to send error notification email: 'ErrorHandler' object has no attribute 'email_config'
2025-05-14 01:12:20,932 - __main__ - INFO - Pipeline stopped by user
2025-05-14 01:13:05,141 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 01:13:05,142 - src.utils.error_handler - ERROR - Failed to load email config: int() argument must be a string, a bytes-like object or a number, not 'NoneType'
2025-05-14 01:13:05,144 - __main__ - INFO - Pipeline initialized successfully
2025-05-14 01:13:05,145 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-14 01:13:05,147 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-14 01:13:05,670 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:13:05,978 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:13:05,978 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:13:06,029 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-14 01:13:06,029 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-14 01:13:06,034 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.

2025-05-14 01:13:07,023 - src.utils.error_handler - ERROR - Failed to send error notification email: please run connect() first
2025-05-14 01:13:07,034 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-14 01:13:07,401 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:13:07,401 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:13:07,401 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:13:07,681 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:13:07,681 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:13:07,681 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:13:07,681 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:13:07,736 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:13:07,736 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:13:07,736 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:13:07,736 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:13:07,740 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.

2025-05-14 01:13:08,576 - src.utils.error_handler - ERROR - Failed to send error notification email: please run connect() first
2025-05-14 01:13:08,587 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-14 01:13:08,608 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:13:08,608 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:13:08,608 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:13:08,608 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:13:08,608 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:13:08,694 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:13:08,694 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:13:08,694 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:13:08,694 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:13:08,694 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:13:08,694 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:13:08,746 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:13:08,746 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:13:08,746 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:13:08,746 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:13:08,746 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:13:08,746 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:13:08,752 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.

2025-05-14 01:13:09,606 - src.utils.error_handler - ERROR - Failed to send error notification email: please run connect() first
2025-05-14 01:13:09,608 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-14 01:13:09,665 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:13:09,665 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:13:09,665 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:13:09,665 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:13:09,665 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:13:09,665 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:13:09,665 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:13:09,709 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:13:09,709 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:13:09,709 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:13:09,709 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:13:09,709 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:13:09,709 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:13:09,709 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:13:09,709 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:13:09,765 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:13:09,765 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:13:09,765 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:13:09,765 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:13:09,765 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:13:09,765 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:13:09,765 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:13:09,765 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:13:09,772 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.

2025-05-14 01:13:10,610 - src.utils.error_handler - ERROR - Failed to send error notification email: please run connect() first
2025-05-14 01:13:10,612 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-14 01:13:11,057 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,057 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,057 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,057 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,057 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,057 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,057 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,057 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,057 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:13:11,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:13:11,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:13:11,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:13:11,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:13:11,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:13:11,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:13:11,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:13:11,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:13:11,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:13:11,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:13:11,251 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.

2025-05-14 01:13:12,118 - src.utils.error_handler - ERROR - Failed to send error notification email: please run connect() first
2025-05-14 01:13:35,293 - __main__ - INFO - Pipeline stopped by user
2025-05-14 01:15:18,102 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 01:15:18,103 - src.utils.error_handler - ERROR - Failed to load email config: int() argument must be a string, a bytes-like object or a number, not 'NoneType'
2025-05-14 01:15:18,105 - __main__ - INFO - Pipeline initialized successfully
2025-05-14 01:15:18,105 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-14 01:15:18,107 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-14 01:15:18,778 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:15:19,094 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:15:19,094 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:15:19,142 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-14 01:15:19,142 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-14 01:15:19,146 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.

2025-05-14 01:15:20,017 - src.utils.error_handler - ERROR - Failed to send error notification email: 'smtp_server'
2025-05-14 01:15:20,029 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-14 01:15:20,407 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:15:20,407 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:15:20,407 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:15:20,670 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:15:20,670 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:15:20,670 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:15:20,670 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:15:20,720 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:15:20,720 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:15:20,720 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:15:20,720 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:15:20,726 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.

2025-05-14 01:15:21,558 - src.utils.error_handler - ERROR - Failed to send error notification email: 'smtp_server'
2025-05-14 01:15:21,569 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-14 01:15:21,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:15:21,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:15:21,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:15:21,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:15:21,586 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:15:21,648 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:15:21,648 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:15:21,648 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:15:21,648 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:15:21,648 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:15:21,648 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:15:21,702 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:15:21,702 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:15:21,702 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:15:21,702 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:15:21,702 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:15:21,702 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:15:21,708 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.

2025-05-14 01:15:22,549 - src.utils.error_handler - ERROR - Failed to send error notification email: 'smtp_server'
2025-05-14 01:15:22,550 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-14 01:15:22,604 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:15:22,604 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:15:22,604 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:15:22,604 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:15:22,604 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:15:22,604 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:15:22,604 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:15:22,649 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:15:22,649 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:15:22,649 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:15:22,649 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:15:22,649 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:15:22,649 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:15:22,649 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:15:22,649 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:15:22,714 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:15:22,714 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:15:22,714 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:15:22,714 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:15:22,714 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:15:22,714 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:15:22,714 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:15:22,714 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:15:22,721 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.

2025-05-14 01:15:23,592 - src.utils.error_handler - ERROR - Failed to send error notification email: 'smtp_server'
2025-05-14 01:15:23,594 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-14 01:15:24,051 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,051 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,051 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,051 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,051 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,051 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,051 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,051 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,051 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,181 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,181 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,181 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,181 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,181 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,181 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,181 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,181 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,181 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,181 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:15:24,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:15:24,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:15:24,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:15:24,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:15:24,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:15:24,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:15:24,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:15:24,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:15:24,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:15:24,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:15:24,247 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.

2025-05-14 01:15:25,083 - src.utils.error_handler - ERROR - Failed to send error notification email: 'smtp_server'
2025-05-14 01:16:05,675 - __main__ - INFO - Pipeline stopped by user
2025-05-14 01:23:16,638 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 01:23:16,640 - src.utils.error_handler - ERROR - Failed to load email config: int() argument must be a string, a bytes-like object or a number, not 'NoneType'
2025-05-14 01:23:16,642 - __main__ - INFO - Pipeline initialized successfully
2025-05-14 01:23:16,643 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-14 01:23:16,644 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-14 01:23:17,229 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:23:17,556 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:23:17,556 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:23:17,604 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-14 01:23:17,604 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-14 01:23:17,608 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.

2025-05-14 01:23:18,493 - src.utils.error_handler - ERROR - Failed to send error notification email: please run connect() first
2025-05-14 01:23:18,506 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-14 01:23:18,910 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:23:18,910 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:23:18,910 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:23:19,236 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:23:19,236 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:23:19,236 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:23:19,236 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:23:19,393 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:23:19,393 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:23:19,393 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:23:19,393 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:23:19,398 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.

2025-05-14 01:23:20,262 - src.utils.error_handler - ERROR - Failed to send error notification email: please run connect() first
2025-05-14 01:23:20,271 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-14 01:23:20,293 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:23:20,293 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:23:20,293 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:23:20,293 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:23:20,293 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:23:20,364 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:23:20,364 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:23:20,364 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:23:20,364 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:23:20,364 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:23:20,364 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:23:20,422 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:23:20,422 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:23:20,422 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:23:20,422 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:23:20,422 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:23:20,422 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:23:20,430 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.

2025-05-14 01:23:21,258 - src.utils.error_handler - ERROR - Failed to send error notification email: please run connect() first
2025-05-14 01:23:21,260 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-14 01:23:21,305 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:23:21,305 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:23:21,305 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:23:21,305 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:23:21,305 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:23:21,305 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:23:21,305 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:23:21,338 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:23:21,338 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:23:21,338 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:23:21,338 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:23:21,338 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:23:21,338 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:23:21,338 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:23:21,338 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:23:21,390 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:23:21,390 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:23:21,390 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:23:21,390 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:23:21,390 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:23:21,390 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:23:21,390 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:23:21,390 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:23:21,399 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.

2025-05-14 01:23:22,229 - src.utils.error_handler - ERROR - Failed to send error notification email: please run connect() first
2025-05-14 01:23:22,231 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-14 01:23:22,626 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,626 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,626 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,626 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,626 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,626 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,626 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,626 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,626 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,730 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,730 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,730 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,730 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,730 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,730 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,730 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,730 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,730 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,730 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:23:22,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:23:22,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:23:22,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:23:22,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:23:22,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:23:22,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:23:22,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:23:22,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:23:22,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:23:22,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:23:22,799 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.

2025-05-14 01:23:23,635 - src.utils.error_handler - ERROR - Failed to send error notification email: please run connect() first
2025-05-14 01:24:28,284 - __main__ - INFO - Pipeline stopped by user
2025-05-14 01:26:52,802 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 01:26:52,803 - src.utils.error_handler - ERROR - Failed to load email config: int() argument must be a string, a bytes-like object or a number, not 'NoneType'
2025-05-14 01:26:52,805 - __main__ - ERROR - Pipeline failed: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-05-14 01:28:44,075 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 01:28:44,077 - __main__ - ERROR - Pipeline failed: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-05-14 01:30:12,698 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 01:30:12,700 - __main__ - ERROR - Pipeline failed: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-05-14 01:30:40,041 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 01:30:40,044 - __main__ - ERROR - Pipeline failed: 'utf-8' codec can't decode byte 0xff in position 0: invalid start byte
2025-05-14 01:34:13,906 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 01:34:13,910 - __main__ - INFO - Pipeline initialized successfully
2025-05-14 01:34:13,910 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-14 01:34:13,912 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-14 01:34:14,453 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:34:14,768 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:34:14,768 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\01\credit_cards_billing.parquet
2025-05-14 01:34:14,821 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-14 01:34:14,821 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-14 01:34:14,826 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\credit_cards_billing /data/2025-05-14/01/credit_cards_billing.parquet' returned non-zero exit status 1.

2025-05-14 01:34:16,573 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 01:34:18,000 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 01:34:18,069 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 01:34:18,079 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-14 01:34:18,521 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:34:18,521 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:34:18,521 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:34:18,813 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:34:18,813 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:34:18,813 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:34:18,813 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\customer_profiles.parquet
2025-05-14 01:34:18,869 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:34:18,869 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:34:18,869 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:34:18,869 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 01:34:18,874 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\customer_profiles /data/2025-05-14/01/customer_profiles.parquet' returned non-zero exit status 1.

2025-05-14 01:34:20,393 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 01:34:22,559 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 01:34:22,619 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 01:34:22,629 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-14 01:34:22,651 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:34:22,651 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:34:22,651 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:34:22,651 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:34:22,651 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\01\loans.parquet
2025-05-14 01:34:22,729 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:34:22,729 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:34:22,729 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:34:22,729 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:34:22,729 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:34:22,729 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\01\loans.parquet
2025-05-14 01:34:22,781 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:34:22,781 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:34:22,781 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:34:22,781 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:34:22,781 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:34:22,781 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
2025-05-14 01:34:22,789 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\loans /data/2025-05-14/01/loans.parquet' returned non-zero exit status 1.

2025-05-14 01:34:24,574 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 01:34:25,698 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 01:34:25,757 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 01:34:25,758 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-14 01:34:25,819 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:34:25,819 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:34:25,819 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:34:25,819 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:34:25,819 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:34:25,819 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:34:25,819 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\01\support_tickets.parquet
2025-05-14 01:34:25,859 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:34:25,859 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:34:25,859 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:34:25,859 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:34:25,859 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:34:25,859 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:34:25,859 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:34:25,859 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\01\support_tickets.parquet
2025-05-14 01:34:25,922 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:34:25,922 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:34:25,922 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:34:25,922 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:34:25,922 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:34:25,922 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:34:25,922 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:34:25,922 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 01:34:25,930 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\support_tickets /data/2025-05-14/01/support_tickets.parquet' returned non-zero exit status 1.

2025-05-14 01:34:27,340 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 01:34:28,521 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 01:34:28,596 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 01:34:28,597 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-14 01:34:29,021 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,021 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,021 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,021 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,021 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,021 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,021 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,021 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,021 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,130 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,130 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,130 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,130 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,130 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,130 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,130 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,130 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,130 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,130 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\01\transactions.parquet
2025-05-14 01:34:29,188 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:34:29,188 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:34:29,188 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:34:29,188 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:34:29,188 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:34:29,188 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:34:29,188 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:34:29,188 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:34:29,188 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:34:29,188 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
2025-05-14 01:34:29,198 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\01\transactions /data/2025-05-14/01/transactions.parquet' returned non-zero exit status 1.

2025-05-14 01:34:30,611 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 01:34:32,671 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 01:34:32,736 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 01:35:00,594 - __main__ - INFO - Pipeline stopped by user
2025-05-14 12:05:20,416 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 12:05:20,421 - __main__ - INFO - Pipeline initialized successfully
2025-05-14 12:05:20,422 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-14 12:09:40,669 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-14 12:09:42,295 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\12\credit_cards_billing.csv
2025-05-14 12:09:46,421 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\12\credit_cards_billing.csv
2025-05-14 12:09:46,421 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\12\credit_cards_billing.csv
2025-05-14 12:09:46,531 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\credit_cards_billing /data/2025-05-14/12/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-14 12:09:46,531 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\credit_cards_billing /data/2025-05-14/12/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-14 12:09:46,540 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\credit_cards_billing /data/2025-05-14/12/credit_cards_billing.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\pipeline\main_pipeline.py", line 170, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\HP\AppData\Local\Programs\Python\Python310\lib\subprocess.py", line 524, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\credit_cards_billing /data/2025-05-14/12/credit_cards_billing.parquet' returned non-zero exit status 1.

2025-05-14 12:09:46,544 - src.utils.error_handler - ERROR - Failed to send error notification email: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'
2025-05-14 12:09:46,568 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-14 12:09:47,848 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\customer_profiles.csv
2025-05-14 12:09:47,848 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\customer_profiles.csv
2025-05-14 12:09:47,848 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\customer_profiles.csv
2025-05-14 12:09:48,535 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\customer_profiles.csv
2025-05-14 12:09:48,535 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\customer_profiles.csv
2025-05-14 12:09:48,535 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\customer_profiles.csv
2025-05-14 12:09:48,535 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\customer_profiles.csv
2025-05-14 12:09:48,560 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\customer_profiles /data/2025-05-14/12/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 12:09:48,560 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\customer_profiles /data/2025-05-14/12/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 12:09:48,560 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\customer_profiles /data/2025-05-14/12/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 12:09:48,560 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\customer_profiles /data/2025-05-14/12/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 12:09:48,566 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\customer_profiles /data/2025-05-14/12/customer_profiles.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\pipeline\main_pipeline.py", line 170, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\HP\AppData\Local\Programs\Python\Python310\lib\subprocess.py", line 524, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\customer_profiles /data/2025-05-14/12/customer_profiles.parquet' returned non-zero exit status 1.

2025-05-14 12:09:48,570 - src.utils.error_handler - ERROR - Failed to send error notification email: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'
2025-05-14 12:09:48,586 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-14 12:09:48,630 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\12\loans.csv
2025-05-14 12:09:48,630 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\12\loans.csv
2025-05-14 12:09:48,630 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\12\loans.csv
2025-05-14 12:09:48,630 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\12\loans.csv
2025-05-14 12:09:48,630 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\12\loans.csv
2025-05-14 12:09:48,725 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\12\loans.csv
2025-05-14 12:09:48,725 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\12\loans.csv
2025-05-14 12:09:48,725 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\12\loans.csv
2025-05-14 12:09:48,725 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\12\loans.csv
2025-05-14 12:09:48,725 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\12\loans.csv
2025-05-14 12:09:48,725 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\12\loans.csv
2025-05-14 12:09:48,758 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\loans /data/2025-05-14/12/loans.parquet' returned non-zero exit status 1.
2025-05-14 12:09:48,758 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\loans /data/2025-05-14/12/loans.parquet' returned non-zero exit status 1.
2025-05-14 12:09:48,758 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\loans /data/2025-05-14/12/loans.parquet' returned non-zero exit status 1.
2025-05-14 12:09:48,758 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\loans /data/2025-05-14/12/loans.parquet' returned non-zero exit status 1.
2025-05-14 12:09:48,758 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\loans /data/2025-05-14/12/loans.parquet' returned non-zero exit status 1.
2025-05-14 12:09:48,758 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\loans /data/2025-05-14/12/loans.parquet' returned non-zero exit status 1.
2025-05-14 12:09:48,763 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\loans /data/2025-05-14/12/loans.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\pipeline\main_pipeline.py", line 170, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\HP\AppData\Local\Programs\Python\Python310\lib\subprocess.py", line 524, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\loans /data/2025-05-14/12/loans.parquet' returned non-zero exit status 1.

2025-05-14 12:09:48,768 - src.utils.error_handler - ERROR - Failed to send error notification email: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'
2025-05-14 12:09:48,776 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-14 12:09:49,088 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\12\support_tickets.csv
2025-05-14 12:09:49,088 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\12\support_tickets.csv
2025-05-14 12:09:49,088 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\12\support_tickets.csv
2025-05-14 12:09:49,088 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\12\support_tickets.csv
2025-05-14 12:09:49,088 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\12\support_tickets.csv
2025-05-14 12:09:49,088 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\12\support_tickets.csv
2025-05-14 12:09:49,088 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\12\support_tickets.csv
2025-05-14 12:09:49,298 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\12\support_tickets.csv
2025-05-14 12:09:49,298 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\12\support_tickets.csv
2025-05-14 12:09:49,298 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\12\support_tickets.csv
2025-05-14 12:09:49,298 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\12\support_tickets.csv
2025-05-14 12:09:49,298 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\12\support_tickets.csv
2025-05-14 12:09:49,298 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\12\support_tickets.csv
2025-05-14 12:09:49,298 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\12\support_tickets.csv
2025-05-14 12:09:49,298 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\12\support_tickets.csv
2025-05-14 12:09:49,368 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 12:09:49,368 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 12:09:49,368 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 12:09:49,368 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 12:09:49,368 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 12:09:49,368 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 12:09:49,368 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 12:09:49,368 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 12:09:49,388 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\pipeline\main_pipeline.py", line 170, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\HP\AppData\Local\Programs\Python\Python310\lib\subprocess.py", line 524, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.

2025-05-14 12:09:49,396 - src.utils.error_handler - ERROR - Failed to send error notification email: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'
2025-05-14 12:09:49,410 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-14 12:09:50,944 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\transactions.csv
2025-05-14 12:09:50,944 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\transactions.csv
2025-05-14 12:09:50,944 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\transactions.csv
2025-05-14 12:09:50,944 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\transactions.csv
2025-05-14 12:09:50,944 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\transactions.csv
2025-05-14 12:09:50,944 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\transactions.csv
2025-05-14 12:09:50,944 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\transactions.csv
2025-05-14 12:09:50,944 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\transactions.csv
2025-05-14 12:09:50,944 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\transactions.csv
2025-05-14 12:09:51,884 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:09:51,884 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:09:51,884 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:09:51,884 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:09:51,884 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:09:51,884 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:09:51,884 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:09:51,884 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:09:51,884 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:09:51,884 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:09:52,099 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:09:52,099 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:09:52,099 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:09:52,099 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:09:52,099 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:09:52,099 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:09:52,099 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:09:52,099 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:09:52,099 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:09:52,099 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:09:52,172 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\pipeline\main_pipeline.py", line 170, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\HP\AppData\Local\Programs\Python\Python310\lib\subprocess.py", line 524, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.

2025-05-14 12:09:52,191 - src.utils.error_handler - ERROR - Failed to send error notification email: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'
2025-05-14 12:13:07,028 - __main__ - INFO - Pipeline stopped by user
2025-05-14 12:53:12,940 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 12:53:12,946 - __main__ - INFO - Pipeline initialized successfully
2025-05-14 12:53:12,946 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-14 12:53:12,948 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-14 12:53:12,949 - src.extractors.csv_extractor - INFO - Started extracting credit_cards_billing from CSV file at incoming_data\2025-05-14\12\credit_cards_billing_processing__1.csv 
2025-05-14 12:53:13,474 - src.extractors.csv_extractor - INFO - Completed extracting credit_cards_billing Number of rows extracted = 200000 , Extracted schema = ['bill_id', 'customer_id', 'month', 'amount_due', 'amount_paid', 'payment_date'] , Partition date = 2025-05-14 , Partition hour = 12 
2025-05-14 12:53:14,955 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\12\credit_cards_billing.csv
2025-05-14 12:53:18,722 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\12\credit_cards_billing.csv
2025-05-14 12:53:18,722 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\12\credit_cards_billing.csv
2025-05-14 12:53:19,165 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\credit_cards_billing /data/2025-05-14/12/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-14 12:53:19,165 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\credit_cards_billing /data/2025-05-14/12/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-14 12:53:19,226 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\credit_cards_billing /data/2025-05-14/12/credit_cards_billing.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\pipeline\main_pipeline.py", line 170, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\HP\AppData\Local\Programs\Python\Python310\lib\subprocess.py", line 524, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\credit_cards_billing /data/2025-05-14/12/credit_cards_billing.parquet' returned non-zero exit status 1.

2025-05-14 12:53:19,234 - src.utils.error_handler - ERROR - Failed to send error notification email: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'
2025-05-14 12:53:19,286 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-14 12:53:19,288 - src.extractors.csv_extractor - INFO - Started extracting customer_profiles from CSV file at incoming_data\2025-05-14\12\customer_profiles_processing__2.csv 
2025-05-14 12:53:19,288 - src.extractors.csv_extractor - INFO - Started extracting customer_profiles from CSV file at incoming_data\2025-05-14\12\customer_profiles_processing__2.csv 
2025-05-14 12:53:19,709 - src.extractors.csv_extractor - INFO - Completed extracting customer_profiles Number of rows extracted = 100000 , Extracted schema = ['customer_id', 'name', 'gender', 'age', 'city', 'account_open_date', 'product_type', 'customer_tier'] , Partition date = 2025-05-14 , Partition hour = 12 
2025-05-14 12:53:19,709 - src.extractors.csv_extractor - INFO - Completed extracting customer_profiles Number of rows extracted = 100000 , Extracted schema = ['customer_id', 'name', 'gender', 'age', 'city', 'account_open_date', 'product_type', 'customer_tier'] , Partition date = 2025-05-14 , Partition hour = 12 
2025-05-14 12:53:20,243 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\customer_profiles.csv
2025-05-14 12:53:20,243 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\customer_profiles.csv
2025-05-14 12:53:20,243 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\customer_profiles.csv
2025-05-14 12:53:21,257 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\customer_profiles.csv
2025-05-14 12:53:21,257 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\customer_profiles.csv
2025-05-14 12:53:21,257 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\customer_profiles.csv
2025-05-14 12:53:21,257 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\customer_profiles.csv
2025-05-14 12:53:21,289 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\customer_profiles /data/2025-05-14/12/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 12:53:21,289 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\customer_profiles /data/2025-05-14/12/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 12:53:21,289 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\customer_profiles /data/2025-05-14/12/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 12:53:21,289 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\customer_profiles /data/2025-05-14/12/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 12:53:21,296 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\customer_profiles /data/2025-05-14/12/customer_profiles.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\pipeline\main_pipeline.py", line 170, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\HP\AppData\Local\Programs\Python\Python310\lib\subprocess.py", line 524, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\customer_profiles /data/2025-05-14/12/customer_profiles.parquet' returned non-zero exit status 1.

2025-05-14 12:53:21,301 - src.utils.error_handler - ERROR - Failed to send error notification email: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'
2025-05-14 12:53:21,320 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-14 12:53:21,323 - src.extractors.txt_extractor - INFO - Started extracting loans from TXT file at incoming_data\2025-05-14\12\loans_processing__3.txt 
2025-05-14 12:53:21,342 - src.extractors.txt_extractor - INFO - Completed extracting loans Number of rows extracted = 1000 , Extracted schema = ['customer_id', 'loan_type', 'amount_utilized', 'utilization_date', 'loan_reason'] , Partition date = 2025-05-14 , Partition hour = 12 
2025-05-14 12:53:21,375 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\12\loans.csv
2025-05-14 12:53:21,375 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\12\loans.csv
2025-05-14 12:53:21,375 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\12\loans.csv
2025-05-14 12:53:21,375 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\12\loans.csv
2025-05-14 12:53:21,375 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\12\loans.csv
2025-05-14 12:53:21,504 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\12\loans.csv
2025-05-14 12:53:21,504 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\12\loans.csv
2025-05-14 12:53:21,504 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\12\loans.csv
2025-05-14 12:53:21,504 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\12\loans.csv
2025-05-14 12:53:21,504 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\12\loans.csv
2025-05-14 12:53:21,504 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\12\loans.csv
2025-05-14 12:53:21,550 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\loans /data/2025-05-14/12/loans.parquet' returned non-zero exit status 1.
2025-05-14 12:53:21,550 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\loans /data/2025-05-14/12/loans.parquet' returned non-zero exit status 1.
2025-05-14 12:53:21,550 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\loans /data/2025-05-14/12/loans.parquet' returned non-zero exit status 1.
2025-05-14 12:53:21,550 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\loans /data/2025-05-14/12/loans.parquet' returned non-zero exit status 1.
2025-05-14 12:53:21,550 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\loans /data/2025-05-14/12/loans.parquet' returned non-zero exit status 1.
2025-05-14 12:53:21,550 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\loans /data/2025-05-14/12/loans.parquet' returned non-zero exit status 1.
2025-05-14 12:53:21,566 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\loans /data/2025-05-14/12/loans.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\pipeline\main_pipeline.py", line 170, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\HP\AppData\Local\Programs\Python\Python310\lib\subprocess.py", line 524, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\loans /data/2025-05-14/12/loans.parquet' returned non-zero exit status 1.

2025-05-14 12:53:21,572 - src.utils.error_handler - ERROR - Failed to send error notification email: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'
2025-05-14 12:53:21,580 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-14 12:53:21,583 - src.extractors.csv_extractor - INFO - Started extracting support_tickets from CSV file at incoming_data\2025-05-14\12\support_tickets_processing__4.csv 
2025-05-14 12:53:21,583 - src.extractors.csv_extractor - INFO - Started extracting support_tickets from CSV file at incoming_data\2025-05-14\12\support_tickets_processing__4.csv 
2025-05-14 12:53:21,583 - src.extractors.csv_extractor - INFO - Started extracting support_tickets from CSV file at incoming_data\2025-05-14\12\support_tickets_processing__4.csv 
2025-05-14 12:53:21,660 - src.extractors.csv_extractor - INFO - Completed extracting support_tickets Number of rows extracted = 15000 , Extracted schema = ['ticket_id', 'customer_id', 'complaint_category', 'complaint_date', 'severity'] , Partition date = 2025-05-14 , Partition hour = 12 
2025-05-14 12:53:21,660 - src.extractors.csv_extractor - INFO - Completed extracting support_tickets Number of rows extracted = 15000 , Extracted schema = ['ticket_id', 'customer_id', 'complaint_category', 'complaint_date', 'severity'] , Partition date = 2025-05-14 , Partition hour = 12 
2025-05-14 12:53:21,660 - src.extractors.csv_extractor - INFO - Completed extracting support_tickets Number of rows extracted = 15000 , Extracted schema = ['ticket_id', 'customer_id', 'complaint_category', 'complaint_date', 'severity'] , Partition date = 2025-05-14 , Partition hour = 12 
2025-05-14 12:53:21,766 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\12\support_tickets.csv
2025-05-14 12:53:21,766 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\12\support_tickets.csv
2025-05-14 12:53:21,766 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\12\support_tickets.csv
2025-05-14 12:53:21,766 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\12\support_tickets.csv
2025-05-14 12:53:21,766 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\12\support_tickets.csv
2025-05-14 12:53:21,766 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\12\support_tickets.csv
2025-05-14 12:53:21,766 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\12\support_tickets.csv
2025-05-14 12:53:21,880 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\12\support_tickets.csv
2025-05-14 12:53:21,880 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\12\support_tickets.csv
2025-05-14 12:53:21,880 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\12\support_tickets.csv
2025-05-14 12:53:21,880 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\12\support_tickets.csv
2025-05-14 12:53:21,880 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\12\support_tickets.csv
2025-05-14 12:53:21,880 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\12\support_tickets.csv
2025-05-14 12:53:21,880 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\12\support_tickets.csv
2025-05-14 12:53:21,880 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\12\support_tickets.csv
2025-05-14 12:53:21,919 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 12:53:21,919 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 12:53:21,919 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 12:53:21,919 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 12:53:21,919 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 12:53:21,919 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 12:53:21,919 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 12:53:21,919 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 12:53:21,935 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\pipeline\main_pipeline.py", line 170, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\HP\AppData\Local\Programs\Python\Python310\lib\subprocess.py", line 524, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\support_tickets /data/2025-05-14/12/support_tickets.parquet' returned non-zero exit status 1.

2025-05-14 12:53:21,941 - src.utils.error_handler - ERROR - Failed to send error notification email: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'
2025-05-14 12:53:21,956 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-14 12:53:22,445 - src.extractors.json_extractor - INFO - Started extracting transactions from JSON file at incoming_data\2025-05-14\12\transactions_processing__5.json 
2025-05-14 12:53:22,875 - src.extractors.json_extractor - INFO - Completed extracting transactions Number of rows extracted = 100000 , Extracted schema = ['sender', 'receiver', 'transaction_amount', 'transaction_date'] , Partition date = 2025-05-14 , Partition hour = 12 
2025-05-14 12:53:23,383 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\transactions.csv
2025-05-14 12:53:23,383 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\transactions.csv
2025-05-14 12:53:23,383 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\transactions.csv
2025-05-14 12:53:23,383 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\transactions.csv
2025-05-14 12:53:23,383 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\transactions.csv
2025-05-14 12:53:23,383 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\transactions.csv
2025-05-14 12:53:23,383 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\transactions.csv
2025-05-14 12:53:23,383 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\transactions.csv
2025-05-14 12:53:23,383 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\12\transactions.csv
2025-05-14 12:53:24,605 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:53:24,605 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:53:24,605 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:53:24,605 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:53:24,605 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:53:24,605 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:53:24,605 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:53:24,605 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:53:24,605 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:53:24,605 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\12\transactions.csv
2025-05-14 12:53:24,660 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:53:24,660 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:53:24,660 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:53:24,660 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:53:24,660 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:53:24,660 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:53:24,660 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:53:24,660 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:53:24,660 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:53:24,660 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
2025-05-14 12:53:24,679 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\pipeline\main_pipeline.py", line 170, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\HP\AppData\Local\Programs\Python\Python310\lib\subprocess.py", line 524, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\12\transactions /data/2025-05-14/12/transactions.parquet' returned non-zero exit status 1.

2025-05-14 12:53:24,686 - src.utils.error_handler - ERROR - Failed to send error notification email: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'
2025-05-14 15:36:19,571 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 15:36:19,576 - src.validators.schema_validator - INFO - Initializing SchemaValidator with schema file: d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\pipeline\..\schema\tables_schema.json
2025-05-14 15:36:19,577 - src.validators.schema_validator - INFO - Successfully loaded schema file with 5 table definitions
2025-05-14 15:36:19,588 - __main__ - INFO - Pipeline initialized successfully
2025-05-14 15:36:19,590 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-14 15:36:19,601 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-14 15:36:19,606 - src.extractors.csv_extractor - INFO - Started extracting credit_cards_billing from CSV file at incoming_data\2025-05-14\15\credit_cards_billing_processing__1.csv 
2025-05-14 15:36:20,364 - src.extractors.csv_extractor - INFO - Completed extracting credit_cards_billing Number of rows extracted = 200000 , Extracted schema = ['bill_id', 'customer_id', 'month', 'amount_due', 'amount_paid', 'payment_date'] , Partition date = 2025-05-14 , Partition hour = 15 
2025-05-14 15:36:20,413 - src.validators.schema_validator - INFO - Starting schema validation for table: credit_cards_billing
2025-05-14 15:36:20,441 - src.validators.schema_validator - INFO - DataFrame shape: (200000, 6)
2025-05-14 15:36:20,452 - src.validators.schema_validator - INFO - Schema validation details:
2025-05-14 15:36:20,457 - src.validators.schema_validator - INFO - - Required columns: ['bill_id', 'customer_id', 'month', 'amount_due', 'amount_paid', 'payment_date']
2025-05-14 15:36:20,462 - src.validators.schema_validator - INFO - - Total columns in schema: 6
2025-05-14 15:36:20,498 - src.validators.schema_validator - INFO - - Total columns in DataFrame: 6
2025-05-14 15:36:20,506 - src.validators.schema_validator - INFO - Starting column type validation
2025-05-14 15:36:20,525 - src.validators.schema_validator - INFO - Column bill_id type validation passed: object
2025-05-14 15:36:20,570 - src.validators.schema_validator - INFO - Column customer_id type validation passed: object
2025-05-14 15:36:20,634 - src.validators.schema_validator - INFO - Column month type validation passed: object
2025-05-14 15:36:20,692 - src.validators.schema_validator - INFO - Column amount_due type validation passed: float64
2025-05-14 15:36:20,721 - src.validators.schema_validator - INFO - Column amount_paid type validation passed: float64
2025-05-14 15:36:20,772 - src.validators.schema_validator - INFO - Column payment_date type validation passed: object
2025-05-14 15:36:20,792 - src.validators.schema_validator - INFO - Schema validation completed successfully for table: credit_cards_billing
2025-05-14 15:36:23,295 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\15\credit_cards_billing.csv
2025-05-14 15:36:26,943 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\15\credit_cards_billing.csv
2025-05-14 15:36:26,943 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\15\credit_cards_billing.csv
2025-05-14 15:36:26,973 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\credit_cards_billing /data/2025-05-14/15/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-14 15:36:26,973 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\credit_cards_billing /data/2025-05-14/15/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-14 15:36:26,982 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\credit_cards_billing /data/2025-05-14/15/credit_cards_billing.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\pipeline\main_pipeline.py", line 170, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\HP\AppData\Local\Programs\Python\Python310\lib\subprocess.py", line 524, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\credit_cards_billing /data/2025-05-14/15/credit_cards_billing.parquet' returned non-zero exit status 1.

2025-05-14 15:36:26,986 - src.utils.error_handler - ERROR - Failed to send error notification email: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'
2025-05-14 15:36:27,019 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-14 15:36:27,024 - src.extractors.csv_extractor - INFO - Started extracting customer_profiles from CSV file at incoming_data\2025-05-14\15\customer_profiles_processing__2.csv 
2025-05-14 15:36:27,024 - src.extractors.csv_extractor - INFO - Started extracting customer_profiles from CSV file at incoming_data\2025-05-14\15\customer_profiles_processing__2.csv 
2025-05-14 15:36:27,867 - src.extractors.csv_extractor - INFO - Completed extracting customer_profiles Number of rows extracted = 100000 , Extracted schema = ['customer_id', 'name', 'gender', 'age', 'city', 'account_open_date', 'product_type', 'customer_tier'] , Partition date = 2025-05-14 , Partition hour = 15 
2025-05-14 15:36:27,867 - src.extractors.csv_extractor - INFO - Completed extracting customer_profiles Number of rows extracted = 100000 , Extracted schema = ['customer_id', 'name', 'gender', 'age', 'city', 'account_open_date', 'product_type', 'customer_tier'] , Partition date = 2025-05-14 , Partition hour = 15 
2025-05-14 15:36:27,872 - src.validators.schema_validator - INFO - Starting schema validation for table: customer_profiles
2025-05-14 15:36:27,873 - src.validators.schema_validator - INFO - DataFrame shape: (100000, 8)
2025-05-14 15:36:27,875 - src.validators.schema_validator - INFO - Schema validation details:
2025-05-14 15:36:27,876 - src.validators.schema_validator - INFO - - Required columns: ['customer_id', 'name', 'gender', 'age', 'city', 'account_open_date', 'product_type', 'customer_tier']
2025-05-14 15:36:27,877 - src.validators.schema_validator - INFO - - Total columns in schema: 8
2025-05-14 15:36:27,878 - src.validators.schema_validator - INFO - - Total columns in DataFrame: 8
2025-05-14 15:36:27,880 - src.validators.schema_validator - INFO - Starting column type validation
2025-05-14 15:36:27,882 - src.validators.schema_validator - INFO - Column customer_id type validation passed: object
2025-05-14 15:36:27,884 - src.validators.schema_validator - INFO - Column name type validation passed: object
2025-05-14 15:36:27,884 - src.validators.schema_validator - INFO - Column gender type validation passed: object
2025-05-14 15:36:27,885 - src.validators.schema_validator - INFO - Column age type validation passed: int64
2025-05-14 15:36:27,892 - src.validators.schema_validator - INFO - Column city type validation passed: object
2025-05-14 15:36:27,894 - src.validators.schema_validator - INFO - Column account_open_date type validation passed: object
2025-05-14 15:36:27,896 - src.validators.schema_validator - INFO - Column product_type type validation passed: object
2025-05-14 15:36:27,897 - src.validators.schema_validator - INFO - Column customer_tier type validation passed: object
2025-05-14 15:36:27,899 - src.validators.schema_validator - INFO - Schema validation completed successfully for table: customer_profiles
2025-05-14 15:36:28,741 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\15\customer_profiles.csv
2025-05-14 15:36:28,741 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\15\customer_profiles.csv
2025-05-14 15:36:28,741 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\15\customer_profiles.csv
2025-05-14 15:36:29,915 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\15\customer_profiles.csv
2025-05-14 15:36:29,915 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\15\customer_profiles.csv
2025-05-14 15:36:29,915 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\15\customer_profiles.csv
2025-05-14 15:36:29,915 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\15\customer_profiles.csv
2025-05-14 15:36:29,949 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\customer_profiles /data/2025-05-14/15/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 15:36:29,949 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\customer_profiles /data/2025-05-14/15/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 15:36:29,949 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\customer_profiles /data/2025-05-14/15/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 15:36:29,949 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\customer_profiles /data/2025-05-14/15/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-14 15:36:29,956 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\customer_profiles /data/2025-05-14/15/customer_profiles.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\pipeline\main_pipeline.py", line 170, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\HP\AppData\Local\Programs\Python\Python310\lib\subprocess.py", line 524, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\customer_profiles /data/2025-05-14/15/customer_profiles.parquet' returned non-zero exit status 1.

2025-05-14 15:36:29,961 - src.utils.error_handler - ERROR - Failed to send error notification email: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'
2025-05-14 15:36:29,971 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-14 15:36:29,973 - src.extractors.txt_extractor - INFO - Started extracting loans from TXT file at incoming_data\2025-05-14\15\loans_processing__3.txt 
2025-05-14 15:36:29,983 - src.extractors.txt_extractor - INFO - Completed extracting loans Number of rows extracted = 1000 , Extracted schema = ['customer_id', 'loan_type', 'amount_utilized', 'utilization_date', 'loan_reason'] , Partition date = 2025-05-14 , Partition hour = 15 
2025-05-14 15:36:29,986 - src.validators.schema_validator - INFO - Starting schema validation for table: loans
2025-05-14 15:36:29,987 - src.validators.schema_validator - INFO - DataFrame shape: (1000, 5)
2025-05-14 15:36:29,988 - src.validators.schema_validator - INFO - Schema validation details:
2025-05-14 15:36:29,989 - src.validators.schema_validator - INFO - - Required columns: ['customer_id', 'loan_type', 'amount_utilized', 'utilization_date', 'loan_reason']
2025-05-14 15:36:29,989 - src.validators.schema_validator - INFO - - Total columns in schema: 5
2025-05-14 15:36:29,990 - src.validators.schema_validator - INFO - - Total columns in DataFrame: 5
2025-05-14 15:36:29,991 - src.validators.schema_validator - INFO - Starting column type validation
2025-05-14 15:36:29,992 - src.validators.schema_validator - INFO - Column customer_id type validation passed: object
2025-05-14 15:36:29,994 - src.validators.schema_validator - INFO - Column loan_type type validation passed: object
2025-05-14 15:36:29,995 - src.validators.schema_validator - INFO - Column amount_utilized type validation passed: int64
2025-05-14 15:36:29,997 - src.validators.schema_validator - INFO - Column utilization_date type validation passed: object
2025-05-14 15:36:29,998 - src.validators.schema_validator - INFO - Column loan_reason type validation passed: object
2025-05-14 15:36:29,999 - src.validators.schema_validator - INFO - Schema validation completed successfully for table: loans
2025-05-14 15:36:30,019 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\15\loans.csv
2025-05-14 15:36:30,019 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\15\loans.csv
2025-05-14 15:36:30,019 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\15\loans.csv
2025-05-14 15:36:30,019 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\15\loans.csv
2025-05-14 15:36:30,019 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\15\loans.csv
2025-05-14 15:36:30,124 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\15\loans.csv
2025-05-14 15:36:30,124 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\15\loans.csv
2025-05-14 15:36:30,124 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\15\loans.csv
2025-05-14 15:36:30,124 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\15\loans.csv
2025-05-14 15:36:30,124 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\15\loans.csv
2025-05-14 15:36:30,124 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\15\loans.csv
2025-05-14 15:36:30,161 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\loans /data/2025-05-14/15/loans.parquet' returned non-zero exit status 1.
2025-05-14 15:36:30,161 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\loans /data/2025-05-14/15/loans.parquet' returned non-zero exit status 1.
2025-05-14 15:36:30,161 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\loans /data/2025-05-14/15/loans.parquet' returned non-zero exit status 1.
2025-05-14 15:36:30,161 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\loans /data/2025-05-14/15/loans.parquet' returned non-zero exit status 1.
2025-05-14 15:36:30,161 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\loans /data/2025-05-14/15/loans.parquet' returned non-zero exit status 1.
2025-05-14 15:36:30,161 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\loans /data/2025-05-14/15/loans.parquet' returned non-zero exit status 1.
2025-05-14 15:36:30,170 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\loans /data/2025-05-14/15/loans.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\pipeline\main_pipeline.py", line 170, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\HP\AppData\Local\Programs\Python\Python310\lib\subprocess.py", line 524, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\loans /data/2025-05-14/15/loans.parquet' returned non-zero exit status 1.

2025-05-14 15:36:30,175 - src.utils.error_handler - ERROR - Failed to send error notification email: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'
2025-05-14 15:36:30,178 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-14 15:36:30,180 - src.extractors.csv_extractor - INFO - Started extracting support_tickets from CSV file at incoming_data\2025-05-14\15\support_tickets_processing__4.csv 
2025-05-14 15:36:30,180 - src.extractors.csv_extractor - INFO - Started extracting support_tickets from CSV file at incoming_data\2025-05-14\15\support_tickets_processing__4.csv 
2025-05-14 15:36:30,180 - src.extractors.csv_extractor - INFO - Started extracting support_tickets from CSV file at incoming_data\2025-05-14\15\support_tickets_processing__4.csv 
2025-05-14 15:36:30,238 - src.extractors.csv_extractor - INFO - Completed extracting support_tickets Number of rows extracted = 15000 , Extracted schema = ['ticket_id', 'customer_id', 'complaint_category', 'complaint_date', 'severity'] , Partition date = 2025-05-14 , Partition hour = 15 
2025-05-14 15:36:30,238 - src.extractors.csv_extractor - INFO - Completed extracting support_tickets Number of rows extracted = 15000 , Extracted schema = ['ticket_id', 'customer_id', 'complaint_category', 'complaint_date', 'severity'] , Partition date = 2025-05-14 , Partition hour = 15 
2025-05-14 15:36:30,238 - src.extractors.csv_extractor - INFO - Completed extracting support_tickets Number of rows extracted = 15000 , Extracted schema = ['ticket_id', 'customer_id', 'complaint_category', 'complaint_date', 'severity'] , Partition date = 2025-05-14 , Partition hour = 15 
2025-05-14 15:36:30,244 - src.validators.schema_validator - INFO - Starting schema validation for table: support_tickets
2025-05-14 15:36:30,246 - src.validators.schema_validator - INFO - DataFrame shape: (15000, 5)
2025-05-14 15:36:30,252 - src.validators.schema_validator - INFO - Schema validation details:
2025-05-14 15:36:30,254 - src.validators.schema_validator - INFO - - Required columns: ['ticket_id', 'customer_id', 'complaint_category', 'complaint_date', 'severity']
2025-05-14 15:36:30,256 - src.validators.schema_validator - INFO - - Total columns in schema: 5
2025-05-14 15:36:30,257 - src.validators.schema_validator - INFO - - Total columns in DataFrame: 5
2025-05-14 15:36:30,260 - src.validators.schema_validator - INFO - Starting column type validation
2025-05-14 15:36:30,261 - src.validators.schema_validator - INFO - Column ticket_id type validation passed: object
2025-05-14 15:36:30,262 - src.validators.schema_validator - INFO - Column customer_id type validation passed: object
2025-05-14 15:36:30,264 - src.validators.schema_validator - INFO - Column complaint_category type validation passed: object
2025-05-14 15:36:30,266 - src.validators.schema_validator - INFO - Column complaint_date type validation passed: object
2025-05-14 15:36:30,267 - src.validators.schema_validator - INFO - Column severity type validation passed: int64
2025-05-14 15:36:30,268 - src.validators.schema_validator - INFO - Schema validation completed successfully for table: support_tickets
2025-05-14 15:36:30,371 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\15\support_tickets.csv
2025-05-14 15:36:30,371 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\15\support_tickets.csv
2025-05-14 15:36:30,371 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\15\support_tickets.csv
2025-05-14 15:36:30,371 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\15\support_tickets.csv
2025-05-14 15:36:30,371 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\15\support_tickets.csv
2025-05-14 15:36:30,371 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\15\support_tickets.csv
2025-05-14 15:36:30,371 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\15\support_tickets.csv
2025-05-14 15:36:30,456 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\15\support_tickets.csv
2025-05-14 15:36:30,456 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\15\support_tickets.csv
2025-05-14 15:36:30,456 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\15\support_tickets.csv
2025-05-14 15:36:30,456 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\15\support_tickets.csv
2025-05-14 15:36:30,456 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\15\support_tickets.csv
2025-05-14 15:36:30,456 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\15\support_tickets.csv
2025-05-14 15:36:30,456 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\15\support_tickets.csv
2025-05-14 15:36:30,456 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\15\support_tickets.csv
2025-05-14 15:36:30,491 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\support_tickets /data/2025-05-14/15/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 15:36:30,491 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\support_tickets /data/2025-05-14/15/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 15:36:30,491 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\support_tickets /data/2025-05-14/15/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 15:36:30,491 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\support_tickets /data/2025-05-14/15/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 15:36:30,491 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\support_tickets /data/2025-05-14/15/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 15:36:30,491 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\support_tickets /data/2025-05-14/15/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 15:36:30,491 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\support_tickets /data/2025-05-14/15/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 15:36:30,491 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\support_tickets /data/2025-05-14/15/support_tickets.parquet' returned non-zero exit status 1.
2025-05-14 15:36:30,500 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\support_tickets /data/2025-05-14/15/support_tickets.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\pipeline\main_pipeline.py", line 170, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\HP\AppData\Local\Programs\Python\Python310\lib\subprocess.py", line 524, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\support_tickets /data/2025-05-14/15/support_tickets.parquet' returned non-zero exit status 1.

2025-05-14 15:36:30,505 - src.utils.error_handler - ERROR - Failed to send error notification email: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'
2025-05-14 15:36:30,509 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-14 15:36:30,886 - src.extractors.json_extractor - INFO - Started extracting transactions from JSON file at incoming_data\2025-05-14\15\transactions_processing__5.json 
2025-05-14 15:36:31,140 - src.extractors.json_extractor - INFO - Completed extracting transactions Number of rows extracted = 100000 , Extracted schema = ['sender', 'receiver', 'transaction_amount', 'transaction_date'] , Partition date = 2025-05-14 , Partition hour = 15 
2025-05-14 15:36:31,158 - src.validators.schema_validator - INFO - Starting schema validation for table: transactions
2025-05-14 15:36:31,162 - src.validators.schema_validator - INFO - DataFrame shape: (100000, 4)
2025-05-14 15:36:31,163 - src.validators.schema_validator - INFO - Schema validation details:
2025-05-14 15:36:31,172 - src.validators.schema_validator - INFO - - Required columns: ['sender', 'receiver', 'transaction_amount', 'transaction_date']
2025-05-14 15:36:31,175 - src.validators.schema_validator - INFO - - Total columns in schema: 4
2025-05-14 15:36:31,179 - src.validators.schema_validator - INFO - - Total columns in DataFrame: 4
2025-05-14 15:36:31,182 - src.validators.schema_validator - INFO - Starting column type validation
2025-05-14 15:36:31,186 - src.validators.schema_validator - INFO - Column sender type validation passed: object
2025-05-14 15:36:31,190 - src.validators.schema_validator - INFO - Column receiver type validation passed: object
2025-05-14 15:36:31,192 - src.validators.schema_validator - INFO - Column transaction_amount type validation passed: int64
2025-05-14 15:36:31,198 - src.validators.schema_validator - INFO - Column transaction_date type validation passed: object
2025-05-14 15:36:31,212 - src.validators.schema_validator - INFO - Schema validation completed successfully for table: transactions
2025-05-14 15:36:31,658 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\15\transactions.csv
2025-05-14 15:36:31,658 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\15\transactions.csv
2025-05-14 15:36:31,658 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\15\transactions.csv
2025-05-14 15:36:31,658 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\15\transactions.csv
2025-05-14 15:36:31,658 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\15\transactions.csv
2025-05-14 15:36:31,658 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\15\transactions.csv
2025-05-14 15:36:31,658 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\15\transactions.csv
2025-05-14 15:36:31,658 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\15\transactions.csv
2025-05-14 15:36:31,658 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\15\transactions.csv
2025-05-14 15:36:32,559 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\15\transactions.csv
2025-05-14 15:36:32,559 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\15\transactions.csv
2025-05-14 15:36:32,559 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\15\transactions.csv
2025-05-14 15:36:32,559 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\15\transactions.csv
2025-05-14 15:36:32,559 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\15\transactions.csv
2025-05-14 15:36:32,559 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\15\transactions.csv
2025-05-14 15:36:32,559 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\15\transactions.csv
2025-05-14 15:36:32,559 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\15\transactions.csv
2025-05-14 15:36:32,559 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\15\transactions.csv
2025-05-14 15:36:32,559 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\15\transactions.csv
2025-05-14 15:36:32,615 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\transactions /data/2025-05-14/15/transactions.parquet' returned non-zero exit status 1.
2025-05-14 15:36:32,615 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\transactions /data/2025-05-14/15/transactions.parquet' returned non-zero exit status 1.
2025-05-14 15:36:32,615 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\transactions /data/2025-05-14/15/transactions.parquet' returned non-zero exit status 1.
2025-05-14 15:36:32,615 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\transactions /data/2025-05-14/15/transactions.parquet' returned non-zero exit status 1.
2025-05-14 15:36:32,615 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\transactions /data/2025-05-14/15/transactions.parquet' returned non-zero exit status 1.
2025-05-14 15:36:32,615 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\transactions /data/2025-05-14/15/transactions.parquet' returned non-zero exit status 1.
2025-05-14 15:36:32,615 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\transactions /data/2025-05-14/15/transactions.parquet' returned non-zero exit status 1.
2025-05-14 15:36:32,615 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\transactions /data/2025-05-14/15/transactions.parquet' returned non-zero exit status 1.
2025-05-14 15:36:32,615 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\transactions /data/2025-05-14/15/transactions.parquet' returned non-zero exit status 1.
2025-05-14 15:36:32,615 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\transactions /data/2025-05-14/15/transactions.parquet' returned non-zero exit status 1.
2025-05-14 15:36:32,630 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\transactions /data/2025-05-14/15/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\pipeline\main_pipeline.py", line 170, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\26 Python\NexaBank_Project\NexaBank-ETL-with-Python-using-OOP\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\HP\AppData\Local\Programs\Python\Python310\lib\subprocess.py", line 524, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-14\15\transactions /data/2025-05-14/15/transactions.parquet' returned non-zero exit status 1.

2025-05-14 15:36:32,635 - src.utils.error_handler - ERROR - Failed to send error notification email: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'
2025-05-14 15:37:50,249 - __main__ - INFO - Pipeline stopped by user
2025-05-14 18:35:32,073 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 18:35:32,076 - src.validators.schema_validator - INFO - Initializing SchemaValidator with schema file: d:\ITI\Python\Project\src\pipeline\..\schema\tables_schema.json
2025-05-14 18:35:32,085 - src.validators.schema_validator - INFO - Successfully loaded schema file with 5 table definitions
2025-05-14 18:35:32,086 - __main__ - INFO - Pipeline initialized successfully
2025-05-14 18:35:32,087 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-14 18:35:32,087 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-14 18:35:32,088 - src.extractors.csv_extractor - INFO - Started extracting credit_cards_billing from CSV file at incoming_data\2025-05-14\18\credit_cards_billing_processing__1.csv 
2025-05-14 18:35:32,450 - src.extractors.csv_extractor - INFO - Completed extracting credit_cards_billing Number of rows extracted = 200000 , Extracted schema = ['bill_id', 'customer_id', 'month', 'amount_due', 'amount_paid', 'payment_date'] , Partition date = 2025-05-14 , Partition hour = 18 
2025-05-14 18:35:32,451 - src.validators.schema_validator - INFO - Starting schema validation for table: credit_cards_billing
2025-05-14 18:35:32,451 - src.validators.schema_validator - INFO - DataFrame shape: (200000, 6)
2025-05-14 18:35:32,452 - src.validators.schema_validator - INFO - Schema validation details:
2025-05-14 18:35:32,453 - src.validators.schema_validator - INFO - - Required columns: ['bill_id', 'customer_id', 'month', 'amount_due', 'amount_paid', 'payment_date']
2025-05-14 18:35:32,453 - src.validators.schema_validator - INFO - - Total columns in schema: 6
2025-05-14 18:35:32,454 - src.validators.schema_validator - INFO - - Total columns in DataFrame: 6
2025-05-14 18:35:32,454 - src.validators.schema_validator - INFO - Starting column type validation
2025-05-14 18:35:32,457 - src.validators.schema_validator - INFO - Column bill_id type validation passed: object
2025-05-14 18:35:32,457 - src.validators.schema_validator - INFO - Column customer_id type validation passed: object
2025-05-14 18:35:32,458 - src.validators.schema_validator - INFO - Column month type validation passed: object
2025-05-14 18:35:32,458 - src.validators.schema_validator - INFO - Column amount_due type validation passed: float64
2025-05-14 18:35:32,459 - src.validators.schema_validator - INFO - Column amount_paid type validation passed: float64
2025-05-14 18:35:32,459 - src.validators.schema_validator - INFO - Column payment_date type validation passed: object
2025-05-14 18:35:32,460 - src.validators.schema_validator - INFO - Schema validation completed successfully for table: credit_cards_billing
2025-05-14 18:35:33,307 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\18\credit_cards_billing.csv
2025-05-14 18:35:35,251 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\18\credit_cards_billing.csv
2025-05-14 18:35:35,251 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\18\credit_cards_billing.csv
2025-05-14 18:35:35,603 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/loaded\2025-05-14\18\credit_cards_billing.parquet
2025-05-14 18:35:35,603 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/loaded\2025-05-14\18\credit_cards_billing.parquet
2025-05-14 18:35:35,603 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/loaded\2025-05-14\18\credit_cards_billing.parquet
2025-05-14 18:35:35,673 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\credit_cards_billing.parquet /user/hive/warehouse/nexabank.db/credit_cards_billing/' returned non-zero exit status 1.
2025-05-14 18:35:35,673 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\credit_cards_billing.parquet /user/hive/warehouse/nexabank.db/credit_cards_billing/' returned non-zero exit status 1.
2025-05-14 18:35:35,673 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\credit_cards_billing.parquet /user/hive/warehouse/nexabank.db/credit_cards_billing/' returned non-zero exit status 1.
2025-05-14 18:35:35,682 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\credit_cards_billing.parquet /user/hive/warehouse/nexabank.db/credit_cards_billing/' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 176, in _process_file
    loaded_writer.upload_to_hdfs(f"{loaded_path}.parquet", hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\credit_cards_billing.parquet /user/hive/warehouse/nexabank.db/credit_cards_billing/' returned non-zero exit status 1.

2025-05-14 18:35:37,420 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 18:35:38,473 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 18:35:38,533 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 18:35:38,543 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-14 18:35:38,544 - src.extractors.csv_extractor - INFO - Started extracting customer_profiles from CSV file at incoming_data\2025-05-14\18\customer_profiles_processing__1.csv 
2025-05-14 18:35:38,544 - src.extractors.csv_extractor - INFO - Started extracting customer_profiles from CSV file at incoming_data\2025-05-14\18\customer_profiles_processing__1.csv 
2025-05-14 18:35:38,776 - src.extractors.csv_extractor - INFO - Completed extracting customer_profiles Number of rows extracted = 100000 , Extracted schema = ['customer_id', 'name', 'gender', 'age', 'city', 'account_open_date', 'product_type', 'customer_tier'] , Partition date = 2025-05-14 , Partition hour = 18 
2025-05-14 18:35:38,776 - src.extractors.csv_extractor - INFO - Completed extracting customer_profiles Number of rows extracted = 100000 , Extracted schema = ['customer_id', 'name', 'gender', 'age', 'city', 'account_open_date', 'product_type', 'customer_tier'] , Partition date = 2025-05-14 , Partition hour = 18 
2025-05-14 18:35:38,778 - src.validators.schema_validator - INFO - Starting schema validation for table: customer_profiles
2025-05-14 18:35:38,779 - src.validators.schema_validator - INFO - DataFrame shape: (100000, 8)
2025-05-14 18:35:38,780 - src.validators.schema_validator - INFO - Schema validation details:
2025-05-14 18:35:38,780 - src.validators.schema_validator - INFO - - Required columns: ['customer_id', 'name', 'gender', 'age', 'city', 'account_open_date', 'product_type', 'customer_tier']
2025-05-14 18:35:38,781 - src.validators.schema_validator - INFO - - Total columns in schema: 8
2025-05-14 18:35:38,782 - src.validators.schema_validator - INFO - - Total columns in DataFrame: 8
2025-05-14 18:35:38,782 - src.validators.schema_validator - INFO - Starting column type validation
2025-05-14 18:35:38,783 - src.validators.schema_validator - INFO - Column customer_id type validation passed: object
2025-05-14 18:35:38,784 - src.validators.schema_validator - INFO - Column name type validation passed: object
2025-05-14 18:35:38,784 - src.validators.schema_validator - INFO - Column gender type validation passed: object
2025-05-14 18:35:38,785 - src.validators.schema_validator - INFO - Column age type validation passed: int64
2025-05-14 18:35:38,785 - src.validators.schema_validator - INFO - Column city type validation passed: object
2025-05-14 18:35:38,786 - src.validators.schema_validator - INFO - Column account_open_date type validation passed: object
2025-05-14 18:35:38,787 - src.validators.schema_validator - INFO - Column product_type type validation passed: object
2025-05-14 18:35:38,788 - src.validators.schema_validator - INFO - Column customer_tier type validation passed: object
2025-05-14 18:35:38,788 - src.validators.schema_validator - INFO - Schema validation completed successfully for table: customer_profiles
2025-05-14 18:35:39,151 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\customer_profiles.csv
2025-05-14 18:35:39,151 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\customer_profiles.csv
2025-05-14 18:35:39,151 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\customer_profiles.csv
2025-05-14 18:35:39,151 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\customer_profiles.csv
2025-05-14 18:35:39,643 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\customer_profiles.csv
2025-05-14 18:35:39,643 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\customer_profiles.csv
2025-05-14 18:35:39,643 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\customer_profiles.csv
2025-05-14 18:35:39,643 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\customer_profiles.csv
2025-05-14 18:35:39,643 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\customer_profiles.csv
2025-05-14 18:35:39,841 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\customer_profiles.parquet
2025-05-14 18:35:39,841 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\customer_profiles.parquet
2025-05-14 18:35:39,841 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\customer_profiles.parquet
2025-05-14 18:35:39,841 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\customer_profiles.parquet
2025-05-14 18:35:39,841 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\customer_profiles.parquet
2025-05-14 18:35:39,841 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\customer_profiles.parquet
2025-05-14 18:35:39,907 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\customer_profiles.parquet /user/hive/warehouse/nexabank.db/customer_profiles/' returned non-zero exit status 1.
2025-05-14 18:35:39,907 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\customer_profiles.parquet /user/hive/warehouse/nexabank.db/customer_profiles/' returned non-zero exit status 1.
2025-05-14 18:35:39,907 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\customer_profiles.parquet /user/hive/warehouse/nexabank.db/customer_profiles/' returned non-zero exit status 1.
2025-05-14 18:35:39,907 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\customer_profiles.parquet /user/hive/warehouse/nexabank.db/customer_profiles/' returned non-zero exit status 1.
2025-05-14 18:35:39,907 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\customer_profiles.parquet /user/hive/warehouse/nexabank.db/customer_profiles/' returned non-zero exit status 1.
2025-05-14 18:35:39,907 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\customer_profiles.parquet /user/hive/warehouse/nexabank.db/customer_profiles/' returned non-zero exit status 1.
2025-05-14 18:35:39,912 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\customer_profiles.parquet /user/hive/warehouse/nexabank.db/customer_profiles/' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 176, in _process_file
    loaded_writer.upload_to_hdfs(f"{loaded_path}.parquet", hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\customer_profiles.parquet /user/hive/warehouse/nexabank.db/customer_profiles/' returned non-zero exit status 1.

2025-05-14 18:35:41,368 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 18:35:42,451 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 18:35:42,521 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 18:35:42,535 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-14 18:35:42,536 - src.extractors.txt_extractor - INFO - Started extracting loans from TXT file at incoming_data\2025-05-14\18\loans_processing__1.txt 
2025-05-14 18:35:42,545 - src.extractors.txt_extractor - INFO - Completed extracting loans Number of rows extracted = 1000 , Extracted schema = ['customer_id', 'loan_type', 'amount_utilized', 'utilization_date', 'loan_reason'] , Partition date = 2025-05-14 , Partition hour = 18 
2025-05-14 18:35:42,546 - src.validators.schema_validator - INFO - Starting schema validation for table: loans
2025-05-14 18:35:42,547 - src.validators.schema_validator - INFO - DataFrame shape: (1000, 5)
2025-05-14 18:35:42,547 - src.validators.schema_validator - INFO - Schema validation details:
2025-05-14 18:35:42,548 - src.validators.schema_validator - INFO - - Required columns: ['customer_id', 'loan_type', 'amount_utilized', 'utilization_date', 'loan_reason']
2025-05-14 18:35:42,548 - src.validators.schema_validator - INFO - - Total columns in schema: 5
2025-05-14 18:35:42,549 - src.validators.schema_validator - INFO - - Total columns in DataFrame: 5
2025-05-14 18:35:42,549 - src.validators.schema_validator - INFO - Starting column type validation
2025-05-14 18:35:42,550 - src.validators.schema_validator - INFO - Column customer_id type validation passed: object
2025-05-14 18:35:42,550 - src.validators.schema_validator - INFO - Column loan_type type validation passed: object
2025-05-14 18:35:42,551 - src.validators.schema_validator - INFO - Column amount_utilized type validation passed: int64
2025-05-14 18:35:42,551 - src.validators.schema_validator - INFO - Column utilization_date type validation passed: object
2025-05-14 18:35:42,551 - src.validators.schema_validator - INFO - Column loan_reason type validation passed: object
2025-05-14 18:35:42,551 - src.validators.schema_validator - INFO - Schema validation completed successfully for table: loans
2025-05-14 18:35:42,564 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\18\loans.csv
2025-05-14 18:35:42,564 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\18\loans.csv
2025-05-14 18:35:42,564 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\18\loans.csv
2025-05-14 18:35:42,564 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\18\loans.csv
2025-05-14 18:35:42,564 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\18\loans.csv
2025-05-14 18:35:42,564 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\18\loans.csv
2025-05-14 18:35:42,564 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\18\loans.csv
2025-05-14 18:35:43,956 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\18\loans.csv
2025-05-14 18:35:43,956 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\18\loans.csv
2025-05-14 18:35:43,956 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\18\loans.csv
2025-05-14 18:35:43,956 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\18\loans.csv
2025-05-14 18:35:43,956 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\18\loans.csv
2025-05-14 18:35:43,956 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\18\loans.csv
2025-05-14 18:35:43,956 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\18\loans.csv
2025-05-14 18:35:43,956 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\18\loans.csv
2025-05-14 18:35:45,135 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/loaded\2025-05-14\18\loans.parquet
2025-05-14 18:35:45,135 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/loaded\2025-05-14\18\loans.parquet
2025-05-14 18:35:45,135 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/loaded\2025-05-14\18\loans.parquet
2025-05-14 18:35:45,135 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/loaded\2025-05-14\18\loans.parquet
2025-05-14 18:35:45,135 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/loaded\2025-05-14\18\loans.parquet
2025-05-14 18:35:45,135 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/loaded\2025-05-14\18\loans.parquet
2025-05-14 18:35:45,135 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/loaded\2025-05-14\18\loans.parquet
2025-05-14 18:35:45,135 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/loaded\2025-05-14\18\loans.parquet
2025-05-14 18:35:45,135 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/loaded\2025-05-14\18\loans.parquet
2025-05-14 18:35:45,294 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
2025-05-14 18:35:45,294 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
2025-05-14 18:35:45,294 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
2025-05-14 18:35:45,294 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
2025-05-14 18:35:45,294 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
2025-05-14 18:35:45,294 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
2025-05-14 18:35:45,294 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
2025-05-14 18:35:45,294 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
2025-05-14 18:35:45,294 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
2025-05-14 18:35:45,303 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 176, in _process_file
    loaded_writer.upload_to_hdfs(f"{loaded_path}.parquet", hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.

2025-05-14 18:35:46,707 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 18:35:47,824 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 18:35:47,883 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 18:35:47,884 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-14 18:35:47,885 - src.extractors.csv_extractor - INFO - Started extracting support_tickets from CSV file at incoming_data\2025-05-14\18\support_tickets_processing__1.csv 
2025-05-14 18:35:47,885 - src.extractors.csv_extractor - INFO - Started extracting support_tickets from CSV file at incoming_data\2025-05-14\18\support_tickets_processing__1.csv 
2025-05-14 18:35:47,885 - src.extractors.csv_extractor - INFO - Started extracting support_tickets from CSV file at incoming_data\2025-05-14\18\support_tickets_processing__1.csv 
2025-05-14 18:35:47,919 - src.extractors.csv_extractor - INFO - Completed extracting support_tickets Number of rows extracted = 15000 , Extracted schema = ['ticket_id', 'customer_id', 'complaint_category', 'complaint_date', 'severity'] , Partition date = 2025-05-14 , Partition hour = 18 
2025-05-14 18:35:47,919 - src.extractors.csv_extractor - INFO - Completed extracting support_tickets Number of rows extracted = 15000 , Extracted schema = ['ticket_id', 'customer_id', 'complaint_category', 'complaint_date', 'severity'] , Partition date = 2025-05-14 , Partition hour = 18 
2025-05-14 18:35:47,919 - src.extractors.csv_extractor - INFO - Completed extracting support_tickets Number of rows extracted = 15000 , Extracted schema = ['ticket_id', 'customer_id', 'complaint_category', 'complaint_date', 'severity'] , Partition date = 2025-05-14 , Partition hour = 18 
2025-05-14 18:35:47,922 - src.validators.schema_validator - INFO - Starting schema validation for table: support_tickets
2025-05-14 18:35:47,923 - src.validators.schema_validator - INFO - DataFrame shape: (15000, 5)
2025-05-14 18:35:47,923 - src.validators.schema_validator - INFO - Schema validation details:
2025-05-14 18:35:47,924 - src.validators.schema_validator - INFO - - Required columns: ['ticket_id', 'customer_id', 'complaint_category', 'complaint_date', 'severity']
2025-05-14 18:35:47,925 - src.validators.schema_validator - INFO - - Total columns in schema: 5
2025-05-14 18:35:47,925 - src.validators.schema_validator - INFO - - Total columns in DataFrame: 5
2025-05-14 18:35:47,926 - src.validators.schema_validator - INFO - Starting column type validation
2025-05-14 18:35:47,926 - src.validators.schema_validator - INFO - Column ticket_id type validation passed: object
2025-05-14 18:35:47,927 - src.validators.schema_validator - INFO - Column customer_id type validation passed: object
2025-05-14 18:35:47,928 - src.validators.schema_validator - INFO - Column complaint_category type validation passed: object
2025-05-14 18:35:47,930 - src.validators.schema_validator - INFO - Column complaint_date type validation passed: object
2025-05-14 18:35:47,931 - src.validators.schema_validator - INFO - Column severity type validation passed: int64
2025-05-14 18:35:47,932 - src.validators.schema_validator - INFO - Schema validation completed successfully for table: support_tickets
2025-05-14 18:35:47,988 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:47,988 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:47,988 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:47,988 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:47,988 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:47,988 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:47,988 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:47,988 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:47,988 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:47,988 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:48,060 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:48,060 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:48,060 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:48,060 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:48,060 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:48,060 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:48,060 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:48,060 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:48,060 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:48,060 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:48,060 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:35:48,090 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:35:48,090 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:35:48,090 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:35:48,090 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:35:48,090 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:35:48,090 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:35:48,090 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:35:48,090 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:35:48,090 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:35:48,090 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:35:48,090 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:35:48,090 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:35:48,157 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:35:48,157 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:35:48,157 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:35:48,157 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:35:48,157 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:35:48,157 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:35:48,157 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:35:48,157 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:35:48,157 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:35:48,157 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:35:48,157 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:35:48,157 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:35:48,165 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 176, in _process_file
    loaded_writer.upload_to_hdfs(f"{loaded_path}.parquet", hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.

2025-05-14 18:35:49,962 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 18:35:50,940 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 18:35:51,002 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 18:35:51,006 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-14 18:35:51,254 - src.extractors.json_extractor - INFO - Started extracting transactions from JSON file at incoming_data\2025-05-14\18\transactions_processing__1.json 
2025-05-14 18:35:51,395 - src.extractors.json_extractor - INFO - Completed extracting transactions Number of rows extracted = 100000 , Extracted schema = ['sender', 'receiver', 'transaction_amount', 'transaction_date'] , Partition date = 2025-05-14 , Partition hour = 18 
2025-05-14 18:35:51,406 - src.validators.schema_validator - INFO - Starting schema validation for table: transactions
2025-05-14 18:35:51,407 - src.validators.schema_validator - INFO - DataFrame shape: (100000, 4)
2025-05-14 18:35:51,407 - src.validators.schema_validator - INFO - Schema validation details:
2025-05-14 18:35:51,408 - src.validators.schema_validator - INFO - - Required columns: ['sender', 'receiver', 'transaction_amount', 'transaction_date']
2025-05-14 18:35:51,408 - src.validators.schema_validator - INFO - - Total columns in schema: 4
2025-05-14 18:35:51,409 - src.validators.schema_validator - INFO - - Total columns in DataFrame: 4
2025-05-14 18:35:51,409 - src.validators.schema_validator - INFO - Starting column type validation
2025-05-14 18:35:51,410 - src.validators.schema_validator - INFO - Column sender type validation passed: object
2025-05-14 18:35:51,411 - src.validators.schema_validator - INFO - Column receiver type validation passed: object
2025-05-14 18:35:51,411 - src.validators.schema_validator - INFO - Column transaction_amount type validation passed: int64
2025-05-14 18:35:51,412 - src.validators.schema_validator - INFO - Column transaction_date type validation passed: object
2025-05-14 18:35:51,412 - src.validators.schema_validator - INFO - Schema validation completed successfully for table: transactions
2025-05-14 18:35:51,630 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:35:51,630 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:35:51,630 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:35:51,630 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:35:51,630 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:35:51,630 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:35:51,630 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:35:51,630 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:35:51,630 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:35:51,630 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:35:51,630 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:35:51,630 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:35:51,630 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:35:52,221 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:35:52,221 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:35:52,221 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:35:52,221 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:35:52,221 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:35:52,221 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:35:52,221 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:35:52,221 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:35:52,221 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:35:52,221 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:35:52,221 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:35:52,221 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:35:52,221 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:35:52,221 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:35:52,360 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:35:52,360 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:35:52,360 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:35:52,360 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:35:52,360 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:35:52,360 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:35:52,360 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:35:52,360 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:35:52,360 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:35:52,360 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:35:52,360 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:35:52,360 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:35:52,360 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:35:52,360 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:35:52,360 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:35:52,425 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:35:52,425 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:35:52,425 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:35:52,425 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:35:52,425 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:35:52,425 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:35:52,425 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:35:52,425 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:35:52,425 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:35:52,425 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:35:52,425 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:35:52,425 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:35:52,425 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:35:52,425 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:35:52,425 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:35:52,436 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 176, in _process_file
    loaded_writer.upload_to_hdfs(f"{loaded_path}.parquet", hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.

2025-05-14 18:35:53,986 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 18:35:54,991 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 18:35:55,060 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 18:36:38,334 - __main__ - INFO - Pipeline stopped by user
2025-05-14 18:37:46,350 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-14 18:37:46,354 - src.validators.schema_validator - INFO - Initializing SchemaValidator with schema file: d:\ITI\Python\Project\src\pipeline\..\schema\tables_schema.json
2025-05-14 18:37:46,356 - src.validators.schema_validator - INFO - Successfully loaded schema file with 5 table definitions
2025-05-14 18:37:46,357 - __main__ - INFO - Pipeline initialized successfully
2025-05-14 18:37:46,358 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-14 18:37:56,360 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: [WinError 183] Cannot create a file when that file already exists: 'incoming_data\\2025-05-14\\18\\credit_cards_billing.csv' -> 'incoming_data\\2025-05-14\\18\\credit_cards_billing_processing__1.csv'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 129, in _process_file
    processing_path = self._mark_file_processing(file_path, seq_num)
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 79, in _mark_file_processing
    os.rename(file_path, new_path)
FileExistsError: [WinError 183] Cannot create a file when that file already exists: 'incoming_data\\2025-05-14\\18\\credit_cards_billing.csv' -> 'incoming_data\\2025-05-14\\18\\credit_cards_billing_processing__1.csv'

2025-05-14 18:37:57,830 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 18:37:58,795 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 18:37:58,860 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 18:37:59,087 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: [WinError 183] Cannot create a file when that file already exists: 'incoming_data\\2025-05-14\\18\\customer_profiles.csv' -> 'incoming_data\\2025-05-14\\18\\customer_profiles_processing__1.csv'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 129, in _process_file
    processing_path = self._mark_file_processing(file_path, seq_num)
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 79, in _mark_file_processing
    os.rename(file_path, new_path)
FileExistsError: [WinError 183] Cannot create a file when that file already exists: 'incoming_data\\2025-05-14\\18\\customer_profiles.csv' -> 'incoming_data\\2025-05-14\\18\\customer_profiles_processing__1.csv'

2025-05-14 18:38:00,744 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 18:38:01,669 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 18:38:01,728 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 18:38:01,729 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: [WinError 183] Cannot create a file when that file already exists: 'incoming_data\\2025-05-14\\18\\loans.txt' -> 'incoming_data\\2025-05-14\\18\\loans_processing__1.txt'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 129, in _process_file
    processing_path = self._mark_file_processing(file_path, seq_num)
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 79, in _mark_file_processing
    os.rename(file_path, new_path)
FileExistsError: [WinError 183] Cannot create a file when that file already exists: 'incoming_data\\2025-05-14\\18\\loans.txt' -> 'incoming_data\\2025-05-14\\18\\loans_processing__1.txt'

2025-05-14 18:38:03,922 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 18:38:05,170 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 18:38:05,234 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 18:38:05,236 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: [WinError 183] Cannot create a file when that file already exists: 'incoming_data\\2025-05-14\\18\\support_tickets.csv' -> 'incoming_data\\2025-05-14\\18\\support_tickets_processing__1.csv'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 129, in _process_file
    processing_path = self._mark_file_processing(file_path, seq_num)
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 79, in _mark_file_processing
    os.rename(file_path, new_path)
FileExistsError: [WinError 183] Cannot create a file when that file already exists: 'incoming_data\\2025-05-14\\18\\support_tickets.csv' -> 'incoming_data\\2025-05-14\\18\\support_tickets_processing__1.csv'

2025-05-14 18:38:06,624 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 18:38:08,154 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 18:38:08,223 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 18:38:08,224 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: [WinError 183] Cannot create a file when that file already exists: 'incoming_data\\2025-05-14\\18\\transactions.json' -> 'incoming_data\\2025-05-14\\18\\transactions_processing__1.json'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 129, in _process_file
    processing_path = self._mark_file_processing(file_path, seq_num)
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 79, in _mark_file_processing
    os.rename(file_path, new_path)
FileExistsError: [WinError 183] Cannot create a file when that file already exists: 'incoming_data\\2025-05-14\\18\\transactions.json' -> 'incoming_data\\2025-05-14\\18\\transactions_processing__1.json'

2025-05-14 18:38:09,598 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 18:38:10,540 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 18:38:10,606 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 18:38:10,607 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-14 18:38:10,609 - src.extractors.csv_extractor - INFO - Started extracting credit_cards_billing from CSV file at incoming_data\2025-05-14\18\credit_cards_billing_processing__2.csv 
2025-05-14 18:38:10,992 - src.extractors.csv_extractor - INFO - Completed extracting credit_cards_billing Number of rows extracted = 200000 , Extracted schema = ['bill_id', 'customer_id', 'month', 'amount_due', 'amount_paid', 'payment_date'] , Partition date = 2025-05-14 , Partition hour = 18 
2025-05-14 18:38:10,996 - src.validators.schema_validator - INFO - Starting schema validation for table: credit_cards_billing
2025-05-14 18:38:10,998 - src.validators.schema_validator - INFO - DataFrame shape: (200000, 6)
2025-05-14 18:38:10,999 - src.validators.schema_validator - INFO - Schema validation details:
2025-05-14 18:38:11,001 - src.validators.schema_validator - INFO - - Required columns: ['bill_id', 'customer_id', 'month', 'amount_due', 'amount_paid', 'payment_date']
2025-05-14 18:38:11,006 - src.validators.schema_validator - INFO - - Total columns in schema: 6
2025-05-14 18:38:11,008 - src.validators.schema_validator - INFO - - Total columns in DataFrame: 6
2025-05-14 18:38:11,013 - src.validators.schema_validator - INFO - Starting column type validation
2025-05-14 18:38:11,016 - src.validators.schema_validator - INFO - Column bill_id type validation passed: object
2025-05-14 18:38:11,022 - src.validators.schema_validator - INFO - Column customer_id type validation passed: object
2025-05-14 18:38:11,024 - src.validators.schema_validator - INFO - Column month type validation passed: object
2025-05-14 18:38:11,027 - src.validators.schema_validator - INFO - Column amount_due type validation passed: float64
2025-05-14 18:38:11,038 - src.validators.schema_validator - INFO - Column amount_paid type validation passed: float64
2025-05-14 18:38:11,041 - src.validators.schema_validator - INFO - Column payment_date type validation passed: object
2025-05-14 18:38:11,043 - src.validators.schema_validator - INFO - Schema validation completed successfully for table: credit_cards_billing
2025-05-14 18:38:11,899 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-14\18\credit_cards_billing.csv
2025-05-14 18:38:13,798 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\18\credit_cards_billing.csv
2025-05-14 18:38:13,798 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-14\18\credit_cards_billing.csv
2025-05-14 18:38:14,045 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/loaded\2025-05-14\18\credit_cards_billing.parquet
2025-05-14 18:38:14,045 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/loaded\2025-05-14\18\credit_cards_billing.parquet
2025-05-14 18:38:14,045 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/loaded\2025-05-14\18\credit_cards_billing.parquet
2025-05-14 18:38:14,113 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\credit_cards_billing.parquet /user/hive/warehouse/nexabank.db/credit_cards_billing/' returned non-zero exit status 1.
2025-05-14 18:38:14,113 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\credit_cards_billing.parquet /user/hive/warehouse/nexabank.db/credit_cards_billing/' returned non-zero exit status 1.
2025-05-14 18:38:14,113 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\credit_cards_billing.parquet /user/hive/warehouse/nexabank.db/credit_cards_billing/' returned non-zero exit status 1.
2025-05-14 18:38:14,118 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\credit_cards_billing.parquet /user/hive/warehouse/nexabank.db/credit_cards_billing/' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 176, in _process_file
    loaded_writer.upload_to_hdfs(f"{loaded_path}.parquet", hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\credit_cards_billing.parquet /user/hive/warehouse/nexabank.db/credit_cards_billing/' returned non-zero exit status 1.

2025-05-14 18:38:15,654 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 18:38:16,665 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 18:38:16,726 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 18:38:16,740 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-14 18:38:16,741 - src.extractors.csv_extractor - INFO - Started extracting customer_profiles from CSV file at incoming_data\2025-05-14\18\customer_profiles_processing__2.csv 
2025-05-14 18:38:16,741 - src.extractors.csv_extractor - INFO - Started extracting customer_profiles from CSV file at incoming_data\2025-05-14\18\customer_profiles_processing__2.csv 
2025-05-14 18:38:16,980 - src.extractors.csv_extractor - INFO - Completed extracting customer_profiles Number of rows extracted = 100000 , Extracted schema = ['customer_id', 'name', 'gender', 'age', 'city', 'account_open_date', 'product_type', 'customer_tier'] , Partition date = 2025-05-14 , Partition hour = 18 
2025-05-14 18:38:16,980 - src.extractors.csv_extractor - INFO - Completed extracting customer_profiles Number of rows extracted = 100000 , Extracted schema = ['customer_id', 'name', 'gender', 'age', 'city', 'account_open_date', 'product_type', 'customer_tier'] , Partition date = 2025-05-14 , Partition hour = 18 
2025-05-14 18:38:16,983 - src.validators.schema_validator - INFO - Starting schema validation for table: customer_profiles
2025-05-14 18:38:16,983 - src.validators.schema_validator - INFO - DataFrame shape: (100000, 8)
2025-05-14 18:38:16,984 - src.validators.schema_validator - INFO - Schema validation details:
2025-05-14 18:38:16,984 - src.validators.schema_validator - INFO - - Required columns: ['customer_id', 'name', 'gender', 'age', 'city', 'account_open_date', 'product_type', 'customer_tier']
2025-05-14 18:38:16,985 - src.validators.schema_validator - INFO - - Total columns in schema: 8
2025-05-14 18:38:16,986 - src.validators.schema_validator - INFO - - Total columns in DataFrame: 8
2025-05-14 18:38:16,986 - src.validators.schema_validator - INFO - Starting column type validation
2025-05-14 18:38:16,987 - src.validators.schema_validator - INFO - Column customer_id type validation passed: object
2025-05-14 18:38:16,988 - src.validators.schema_validator - INFO - Column name type validation passed: object
2025-05-14 18:38:16,989 - src.validators.schema_validator - INFO - Column gender type validation passed: object
2025-05-14 18:38:16,990 - src.validators.schema_validator - INFO - Column age type validation passed: int64
2025-05-14 18:38:16,991 - src.validators.schema_validator - INFO - Column city type validation passed: object
2025-05-14 18:38:16,991 - src.validators.schema_validator - INFO - Column account_open_date type validation passed: object
2025-05-14 18:38:16,992 - src.validators.schema_validator - INFO - Column product_type type validation passed: object
2025-05-14 18:38:16,993 - src.validators.schema_validator - INFO - Column customer_tier type validation passed: object
2025-05-14 18:38:16,994 - src.validators.schema_validator - INFO - Schema validation completed successfully for table: customer_profiles
2025-05-14 18:38:17,427 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\customer_profiles.csv
2025-05-14 18:38:17,427 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\customer_profiles.csv
2025-05-14 18:38:17,427 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\customer_profiles.csv
2025-05-14 18:38:17,427 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\customer_profiles.csv
2025-05-14 18:38:17,972 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\customer_profiles.csv
2025-05-14 18:38:17,972 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\customer_profiles.csv
2025-05-14 18:38:17,972 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\customer_profiles.csv
2025-05-14 18:38:17,972 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\customer_profiles.csv
2025-05-14 18:38:17,972 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\customer_profiles.csv
2025-05-14 18:38:18,168 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\customer_profiles.parquet
2025-05-14 18:38:18,168 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\customer_profiles.parquet
2025-05-14 18:38:18,168 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\customer_profiles.parquet
2025-05-14 18:38:18,168 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\customer_profiles.parquet
2025-05-14 18:38:18,168 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\customer_profiles.parquet
2025-05-14 18:38:18,168 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\customer_profiles.parquet
2025-05-14 18:38:18,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\customer_profiles.parquet /user/hive/warehouse/nexabank.db/customer_profiles/' returned non-zero exit status 1.
2025-05-14 18:38:18,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\customer_profiles.parquet /user/hive/warehouse/nexabank.db/customer_profiles/' returned non-zero exit status 1.
2025-05-14 18:38:18,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\customer_profiles.parquet /user/hive/warehouse/nexabank.db/customer_profiles/' returned non-zero exit status 1.
2025-05-14 18:38:18,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\customer_profiles.parquet /user/hive/warehouse/nexabank.db/customer_profiles/' returned non-zero exit status 1.
2025-05-14 18:38:18,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\customer_profiles.parquet /user/hive/warehouse/nexabank.db/customer_profiles/' returned non-zero exit status 1.
2025-05-14 18:38:18,239 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\customer_profiles.parquet /user/hive/warehouse/nexabank.db/customer_profiles/' returned non-zero exit status 1.
2025-05-14 18:38:18,245 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\customer_profiles.parquet /user/hive/warehouse/nexabank.db/customer_profiles/' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 176, in _process_file
    loaded_writer.upload_to_hdfs(f"{loaded_path}.parquet", hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\customer_profiles.parquet /user/hive/warehouse/nexabank.db/customer_profiles/' returned non-zero exit status 1.

2025-05-14 18:38:19,679 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 18:38:20,689 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 18:38:20,754 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 18:38:20,761 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-14 18:38:20,762 - src.extractors.txt_extractor - INFO - Started extracting loans from TXT file at incoming_data\2025-05-14\18\loans_processing__2.txt 
2025-05-14 18:38:20,773 - src.extractors.txt_extractor - INFO - Completed extracting loans Number of rows extracted = 1000 , Extracted schema = ['customer_id', 'loan_type', 'amount_utilized', 'utilization_date', 'loan_reason'] , Partition date = 2025-05-14 , Partition hour = 18 
2025-05-14 18:38:20,774 - src.validators.schema_validator - INFO - Starting schema validation for table: loans
2025-05-14 18:38:20,775 - src.validators.schema_validator - INFO - DataFrame shape: (1000, 5)
2025-05-14 18:38:20,776 - src.validators.schema_validator - INFO - Schema validation details:
2025-05-14 18:38:20,776 - src.validators.schema_validator - INFO - - Required columns: ['customer_id', 'loan_type', 'amount_utilized', 'utilization_date', 'loan_reason']
2025-05-14 18:38:20,777 - src.validators.schema_validator - INFO - - Total columns in schema: 5
2025-05-14 18:38:20,778 - src.validators.schema_validator - INFO - - Total columns in DataFrame: 5
2025-05-14 18:38:20,778 - src.validators.schema_validator - INFO - Starting column type validation
2025-05-14 18:38:20,779 - src.validators.schema_validator - INFO - Column customer_id type validation passed: object
2025-05-14 18:38:20,780 - src.validators.schema_validator - INFO - Column loan_type type validation passed: object
2025-05-14 18:38:20,781 - src.validators.schema_validator - INFO - Column amount_utilized type validation passed: int64
2025-05-14 18:38:20,782 - src.validators.schema_validator - INFO - Column utilization_date type validation passed: object
2025-05-14 18:38:20,782 - src.validators.schema_validator - INFO - Column loan_reason type validation passed: object
2025-05-14 18:38:20,783 - src.validators.schema_validator - INFO - Schema validation completed successfully for table: loans
2025-05-14 18:38:20,792 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\18\loans.csv
2025-05-14 18:38:20,792 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\18\loans.csv
2025-05-14 18:38:20,792 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\18\loans.csv
2025-05-14 18:38:20,792 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\18\loans.csv
2025-05-14 18:38:20,792 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\18\loans.csv
2025-05-14 18:38:20,792 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\18\loans.csv
2025-05-14 18:38:20,792 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-14\18\loans.csv
2025-05-14 18:38:20,854 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\18\loans.csv
2025-05-14 18:38:20,854 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\18\loans.csv
2025-05-14 18:38:20,854 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\18\loans.csv
2025-05-14 18:38:20,854 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\18\loans.csv
2025-05-14 18:38:20,854 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\18\loans.csv
2025-05-14 18:38:20,854 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\18\loans.csv
2025-05-14 18:38:20,854 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\18\loans.csv
2025-05-14 18:38:20,854 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/transformed\2025-05-14\18\loans.csv
2025-05-14 18:38:20,870 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/loaded\2025-05-14\18\loans.parquet
2025-05-14 18:38:20,870 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/loaded\2025-05-14\18\loans.parquet
2025-05-14 18:38:20,870 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/loaded\2025-05-14\18\loans.parquet
2025-05-14 18:38:20,870 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/loaded\2025-05-14\18\loans.parquet
2025-05-14 18:38:20,870 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/loaded\2025-05-14\18\loans.parquet
2025-05-14 18:38:20,870 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/loaded\2025-05-14\18\loans.parquet
2025-05-14 18:38:20,870 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/loaded\2025-05-14\18\loans.parquet
2025-05-14 18:38:20,870 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/loaded\2025-05-14\18\loans.parquet
2025-05-14 18:38:20,870 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/loaded\2025-05-14\18\loans.parquet
2025-05-14 18:38:20,943 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
2025-05-14 18:38:20,943 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
2025-05-14 18:38:20,943 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
2025-05-14 18:38:20,943 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
2025-05-14 18:38:20,943 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
2025-05-14 18:38:20,943 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
2025-05-14 18:38:20,943 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
2025-05-14 18:38:20,943 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
2025-05-14 18:38:20,943 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
2025-05-14 18:38:20,952 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 176, in _process_file
    loaded_writer.upload_to_hdfs(f"{loaded_path}.parquet", hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\loans.parquet /user/hive/warehouse/nexabank.db/loans/' returned non-zero exit status 1.

2025-05-14 18:38:22,414 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 18:38:23,470 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 18:38:23,538 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 18:38:23,539 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-14 18:38:23,540 - src.extractors.csv_extractor - INFO - Started extracting support_tickets from CSV file at incoming_data\2025-05-14\18\support_tickets_processing__2.csv 
2025-05-14 18:38:23,540 - src.extractors.csv_extractor - INFO - Started extracting support_tickets from CSV file at incoming_data\2025-05-14\18\support_tickets_processing__2.csv 
2025-05-14 18:38:23,540 - src.extractors.csv_extractor - INFO - Started extracting support_tickets from CSV file at incoming_data\2025-05-14\18\support_tickets_processing__2.csv 
2025-05-14 18:38:23,564 - src.extractors.csv_extractor - INFO - Completed extracting support_tickets Number of rows extracted = 15000 , Extracted schema = ['ticket_id', 'customer_id', 'complaint_category', 'complaint_date', 'severity'] , Partition date = 2025-05-14 , Partition hour = 18 
2025-05-14 18:38:23,564 - src.extractors.csv_extractor - INFO - Completed extracting support_tickets Number of rows extracted = 15000 , Extracted schema = ['ticket_id', 'customer_id', 'complaint_category', 'complaint_date', 'severity'] , Partition date = 2025-05-14 , Partition hour = 18 
2025-05-14 18:38:23,564 - src.extractors.csv_extractor - INFO - Completed extracting support_tickets Number of rows extracted = 15000 , Extracted schema = ['ticket_id', 'customer_id', 'complaint_category', 'complaint_date', 'severity'] , Partition date = 2025-05-14 , Partition hour = 18 
2025-05-14 18:38:23,568 - src.validators.schema_validator - INFO - Starting schema validation for table: support_tickets
2025-05-14 18:38:23,569 - src.validators.schema_validator - INFO - DataFrame shape: (15000, 5)
2025-05-14 18:38:23,570 - src.validators.schema_validator - INFO - Schema validation details:
2025-05-14 18:38:23,571 - src.validators.schema_validator - INFO - - Required columns: ['ticket_id', 'customer_id', 'complaint_category', 'complaint_date', 'severity']
2025-05-14 18:38:23,571 - src.validators.schema_validator - INFO - - Total columns in schema: 5
2025-05-14 18:38:23,572 - src.validators.schema_validator - INFO - - Total columns in DataFrame: 5
2025-05-14 18:38:23,573 - src.validators.schema_validator - INFO - Starting column type validation
2025-05-14 18:38:23,573 - src.validators.schema_validator - INFO - Column ticket_id type validation passed: object
2025-05-14 18:38:23,574 - src.validators.schema_validator - INFO - Column customer_id type validation passed: object
2025-05-14 18:38:23,575 - src.validators.schema_validator - INFO - Column complaint_category type validation passed: object
2025-05-14 18:38:23,576 - src.validators.schema_validator - INFO - Column complaint_date type validation passed: object
2025-05-14 18:38:23,577 - src.validators.schema_validator - INFO - Column severity type validation passed: int64
2025-05-14 18:38:23,578 - src.validators.schema_validator - INFO - Schema validation completed successfully for table: support_tickets
2025-05-14 18:38:23,615 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,615 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,615 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,615 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,615 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,615 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,615 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,615 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,615 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,615 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,672 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,672 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,672 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,672 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,672 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,672 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,672 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,672 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,672 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,672 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,672 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-14\18\support_tickets.csv
2025-05-14 18:38:23,701 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:38:23,701 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:38:23,701 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:38:23,701 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:38:23,701 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:38:23,701 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:38:23,701 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:38:23,701 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:38:23,701 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:38:23,701 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:38:23,701 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:38:23,701 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/loaded\2025-05-14\18\support_tickets.parquet
2025-05-14 18:38:23,773 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:38:23,773 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:38:23,773 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:38:23,773 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:38:23,773 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:38:23,773 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:38:23,773 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:38:23,773 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:38:23,773 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:38:23,773 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:38:23,773 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:38:23,773 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
2025-05-14 18:38:23,785 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 176, in _process_file
    loaded_writer.upload_to_hdfs(f"{loaded_path}.parquet", hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\support_tickets.parquet /user/hive/warehouse/nexabank.db/support_tickets/' returned non-zero exit status 1.

2025-05-14 18:38:25,163 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 18:38:26,078 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 18:38:26,141 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 18:38:26,143 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-14 18:38:26,362 - src.extractors.json_extractor - INFO - Started extracting transactions from JSON file at incoming_data\2025-05-14\18\transactions_processing__2.json 
2025-05-14 18:38:26,473 - src.extractors.json_extractor - INFO - Completed extracting transactions Number of rows extracted = 100000 , Extracted schema = ['sender', 'receiver', 'transaction_amount', 'transaction_date'] , Partition date = 2025-05-14 , Partition hour = 18 
2025-05-14 18:38:26,482 - src.validators.schema_validator - INFO - Starting schema validation for table: transactions
2025-05-14 18:38:26,483 - src.validators.schema_validator - INFO - DataFrame shape: (100000, 4)
2025-05-14 18:38:26,484 - src.validators.schema_validator - INFO - Schema validation details:
2025-05-14 18:38:26,484 - src.validators.schema_validator - INFO - - Required columns: ['sender', 'receiver', 'transaction_amount', 'transaction_date']
2025-05-14 18:38:26,485 - src.validators.schema_validator - INFO - - Total columns in schema: 4
2025-05-14 18:38:26,486 - src.validators.schema_validator - INFO - - Total columns in DataFrame: 4
2025-05-14 18:38:26,486 - src.validators.schema_validator - INFO - Starting column type validation
2025-05-14 18:38:26,487 - src.validators.schema_validator - INFO - Column sender type validation passed: object
2025-05-14 18:38:26,488 - src.validators.schema_validator - INFO - Column receiver type validation passed: object
2025-05-14 18:38:26,488 - src.validators.schema_validator - INFO - Column transaction_amount type validation passed: int64
2025-05-14 18:38:26,489 - src.validators.schema_validator - INFO - Column transaction_date type validation passed: object
2025-05-14 18:38:26,490 - src.validators.schema_validator - INFO - Schema validation completed successfully for table: transactions
2025-05-14 18:38:26,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:38:26,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:38:26,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:38:26,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:38:26,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:38:26,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:38:26,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:38:26,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:38:26,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:38:26,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:38:26,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:38:26,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:38:26,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-14\18\transactions.csv
2025-05-14 18:38:27,101 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:38:27,101 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:38:27,101 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:38:27,101 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:38:27,101 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:38:27,101 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:38:27,101 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:38:27,101 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:38:27,101 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:38:27,101 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:38:27,101 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:38:27,101 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:38:27,101 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:38:27,101 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-14\18\transactions.csv
2025-05-14 18:38:27,212 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:38:27,212 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:38:27,212 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:38:27,212 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:38:27,212 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:38:27,212 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:38:27,212 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:38:27,212 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:38:27,212 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:38:27,212 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:38:27,212 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:38:27,212 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:38:27,212 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:38:27,212 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:38:27,212 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/loaded\2025-05-14\18\transactions.parquet
2025-05-14 18:38:27,284 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:38:27,284 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:38:27,284 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:38:27,284 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:38:27,284 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:38:27,284 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:38:27,284 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:38:27,284 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:38:27,284 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:38:27,284 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:38:27,284 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:38:27,284 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:38:27,284 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:38:27,284 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:38:27,284 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
2025-05-14 18:38:27,298 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 176, in _process_file
    loaded_writer.upload_to_hdfs(f"{loaded_path}.parquet", hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/loaded\2025-05-14\18\transactions.parquet /user/hive/warehouse/nexabank.db/transactions/' returned non-zero exit status 1.

2025-05-14 18:38:28,714 - src.utils.error_handler - INFO - Connected to email server
2025-05-14 18:38:30,812 - src.utils.error_handler - INFO - Mail sent successfully to bassanti355@gmail.com
2025-05-14 18:38:30,957 - src.utils.error_handler - INFO - Disconnected from email server
2025-05-14 18:46:43,431 - __main__ - INFO - Pipeline stopped by user
