2025-05-13 21:14:15,600 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-13 21:14:15,602 - src.utils.error_handler - ERROR - Failed to load email config: [Errno 2] No such file or directory: 'config/email_config.txt'
2025-05-13 21:14:15,604 - src.validators.schema_validator - ERROR - Failed to load schema file: [Errno 2] No such file or directory: '..\\schema\\tables_schema.json'
2025-05-13 21:14:15,605 - __main__ - ERROR - Pipeline failed: [Errno 2] No such file or directory: '..\\schema\\tables_schema.json'
2025-05-13 21:43:22,628 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-13 21:43:22,629 - src.utils.error_handler - ERROR - Failed to load email config: not enough values to unpack (expected 2, got 1)
2025-05-13 21:43:22,631 - src.validators.schema_validator - ERROR - Failed to load schema file: [Errno 2] No such file or directory: 'd:\\ITI\\Python\\Project\\schema\\tables_schema.json'
2025-05-13 21:43:22,632 - __main__ - ERROR - Pipeline failed: [Errno 2] No such file or directory: 'd:\\ITI\\Python\\Project\\schema\\tables_schema.json'
2025-05-13 21:44:56,447 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-13 21:44:56,448 - src.utils.error_handler - ERROR - Failed to load email config: not enough values to unpack (expected 2, got 1)
2025-05-13 21:44:56,449 - src.validators.schema_validator - ERROR - Failed to load schema file: [Errno 2] No such file or directory: 'schema\\tables_schema.json'
2025-05-13 21:44:56,450 - __main__ - ERROR - Pipeline failed: [Errno 2] No such file or directory: 'schema\\tables_schema.json'
2025-05-13 22:45:02,586 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-13 22:45:02,589 - __main__ - INFO - Pipeline initialized successfully
2025-05-13 22:45:02,589 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-13 22:45:02,590 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-13 22:45:03,522 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\22\credit_cards_billing.parquet
2025-05-13 22:45:03,539 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: 'due_date'
Traceback (most recent call last):
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\indexes\base.py", line 3805, in get_loc
    return self._engine.get_loc(casted_key)
  File "index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas\\_libs\\hashtable_class_helper.pxi", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas\\_libs\\hashtable_class_helper.pxi", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'due_date'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\credit_cards_billing_transformer.py", line 22, in transform
    df['late_days'] = (df['payment_date'] - df['due_date']).dt.days
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\frame.py", line 4102, in __getitem__
    indexer = self.columns.get_loc(key)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\indexes\base.py", line 3812, in get_loc
    raise KeyError(key) from err
KeyError: 'due_date'

2025-05-13 22:45:05,322 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442cd34bef4sm226522465e9.24 - gsmtp')
2025-05-13 22:45:05,323 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-13 22:45:05,737 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\22\customer_profiles.parquet
2025-05-13 22:45:05,737 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\22\customer_profiles.parquet
2025-05-13 22:45:05,772 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: unsupported operand type(s) for -: 'str' and 'str'
Traceback (most recent call last):
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 218, in _na_arithmetic_op
    result = func(left, right)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\roperator.py", line 15, in rsub
    return right - left
TypeError: unsupported operand type(s) for -: 'str' and 'str'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\customer_profile_transformer.py", line 17, in transform
    df['tenure'] = (self.partition_date - df['account_open_date']).dt.days // 365
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\common.py", line 76, in new_method
    return method(self, other)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\arraylike.py", line 198, in __rsub__
    return self._arith_method(other, roperator.rsub)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\series.py", line 6135, in _arith_method
    return base.IndexOpsMixin._arith_method(self, other, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\base.py", line 1382, in _arith_method
    result = ops.arithmetic_op(lvalues, rvalues, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 283, in arithmetic_op
    res_values = _na_arithmetic_op(left, right, op)  # type: ignore[arg-type]
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 227, in _na_arithmetic_op
    result = _masked_arith_op(left, right, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 182, in _masked_arith_op
    result[mask] = op(xrav[mask], y)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\roperator.py", line 15, in rsub
    return right - left
TypeError: unsupported operand type(s) for -: 'str' and 'str'

2025-05-13 22:45:07,364 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442d67e0ff1sm176656405e9.14 - gsmtp')
2025-05-13 22:45:07,367 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-13 22:45:07,385 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\22\loans.parquet
2025-05-13 22:45:07,385 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\22\loans.parquet
2025-05-13 22:45:07,385 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\22\loans.parquet
2025-05-13 22:45:07,390 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: unsupported operand type(s) for -: 'str' and 'str'
Traceback (most recent call last):
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 218, in _na_arithmetic_op
    result = func(left, right)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\roperator.py", line 15, in rsub
    return right - left
TypeError: unsupported operand type(s) for -: 'str' and 'str'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\loans_transformer.py", line 19, in transform
    df['age'] = (self.partition_date - df['utilization_date']).dt.days
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\common.py", line 76, in new_method
    return method(self, other)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\arraylike.py", line 198, in __rsub__
    return self._arith_method(other, roperator.rsub)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\series.py", line 6135, in _arith_method
    return base.IndexOpsMixin._arith_method(self, other, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\base.py", line 1382, in _arith_method
    result = ops.arithmetic_op(lvalues, rvalues, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 283, in arithmetic_op
    res_values = _na_arithmetic_op(left, right, op)  # type: ignore[arg-type]
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 227, in _na_arithmetic_op
    result = _masked_arith_op(left, right, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 182, in _masked_arith_op
    result[mask] = op(xrav[mask], y)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\roperator.py", line 15, in rsub
    return right - left
TypeError: unsupported operand type(s) for -: 'str' and 'str'

2025-05-13 22:45:08,955 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442d67ee33bsm176975025e9.20 - gsmtp')
2025-05-13 22:45:08,957 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-13 22:45:09,015 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\22\support_tickets.parquet
2025-05-13 22:45:09,015 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\22\support_tickets.parquet
2025-05-13 22:45:09,015 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\22\support_tickets.parquet
2025-05-13 22:45:09,015 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\22\support_tickets.parquet
2025-05-13 22:45:09,020 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: 'issue_date'
Traceback (most recent call last):
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\indexes\base.py", line 3805, in get_loc
    return self._engine.get_loc(casted_key)
  File "index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas\\_libs\\hashtable_class_helper.pxi", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas\\_libs\\hashtable_class_helper.pxi", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'issue_date'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\support_tickets_transformer.py", line 16, in transform
    df['age'] = (self.partition_date - df['issue_date']).dt.days
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\frame.py", line 4102, in __getitem__
    indexer = self.columns.get_loc(key)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\indexes\base.py", line 3812, in get_loc
    raise KeyError(key) from err
KeyError: 'issue_date'

2025-05-13 22:45:11,684 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f579aa5bsm17159724f8f.0 - gsmtp')
2025-05-13 22:45:11,686 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-13 22:45:12,117 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\22\transactions.parquet
2025-05-13 22:45:12,117 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\22\transactions.parquet
2025-05-13 22:45:12,117 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\22\transactions.parquet
2025-05-13 22:45:12,117 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\22\transactions.parquet
2025-05-13 22:45:12,117 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\22\transactions.parquet
2025-05-13 22:45:12,241 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\22\transactions.parquet
2025-05-13 22:45:12,241 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\22\transactions.parquet
2025-05-13 22:45:12,241 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\22\transactions.parquet
2025-05-13 22:45:12,241 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\22\transactions.parquet
2025-05-13 22:45:12,241 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\22\transactions.parquet
2025-05-13 22:45:12,241 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\22\transactions.parquet
2025-05-13 22:45:12,294 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\22\transactions /data/2025-05-13/22/transactions.parquet' returned non-zero exit status 1.
2025-05-13 22:45:12,294 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\22\transactions /data/2025-05-13/22/transactions.parquet' returned non-zero exit status 1.
2025-05-13 22:45:12,294 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\22\transactions /data/2025-05-13/22/transactions.parquet' returned non-zero exit status 1.
2025-05-13 22:45:12,294 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\22\transactions /data/2025-05-13/22/transactions.parquet' returned non-zero exit status 1.
2025-05-13 22:45:12,294 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\22\transactions /data/2025-05-13/22/transactions.parquet' returned non-zero exit status 1.
2025-05-13 22:45:12,294 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\22\transactions /data/2025-05-13/22/transactions.parquet' returned non-zero exit status 1.
2025-05-13 22:45:12,302 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\22\transactions /data/2025-05-13/22/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\22\transactions /data/2025-05-13/22/transactions.parquet' returned non-zero exit status 1.

2025-05-13 22:45:13,795 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442cd3af15bsm224092915e9.30 - gsmtp')
2025-05-13 22:45:18,867 - __main__ - INFO - Pipeline stopped by user
2025-05-13 22:59:18,459 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-13 22:59:18,461 - __main__ - INFO - Pipeline initialized successfully
2025-05-13 22:59:18,462 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-13 22:59:18,462 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-13 22:59:19,099 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\22\credit_cards_billing.parquet
2025-05-13 22:59:19,193 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: cannot subtract DatetimeArray from ndarray
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\credit_cards_billing_transformer.py", line 22, in transform
    df['late_days'] = (df['payment_date'] - df['due_date']).dt.days
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\common.py", line 76, in new_method
    return method(self, other)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\arraylike.py", line 194, in __sub__
    return self._arith_method(other, operator.sub)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\series.py", line 6135, in _arith_method
    return base.IndexOpsMixin._arith_method(self, other, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\base.py", line 1382, in _arith_method
    result = ops.arithmetic_op(lvalues, rvalues, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 273, in arithmetic_op
    res_values = op(left, right)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\arrays\datetimelike.py", line 2200, in __array_ufunc__
    return super().__array_ufunc__(ufunc, method, *inputs, **kwargs)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\arrays\base.py", line 2282, in __array_ufunc__
    result = arraylike.maybe_dispatch_ufunc_to_dunder_op(
  File "ops_dispatch.pyx", line 113, in pandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\arrays\datetimelike.py", line 1499, in __rsub__
    raise TypeError(
TypeError: cannot subtract DatetimeArray from ndarray

2025-05-13 22:59:21,228 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f5a5a2e0sm17095098f8f.101 - gsmtp')
2025-05-13 22:59:21,232 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-13 22:59:21,687 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\22\customer_profiles.parquet
2025-05-13 22:59:21,687 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\22\customer_profiles.parquet
2025-05-13 22:59:21,689 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: 'str' object has no attribute 'to_datetime'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\customer_profile_transformer.py", line 17, in transform
    df['tenure'] = (self.partition_date.to_datetime() - df['account_open_date'].to_datetime()   ).dt.days // 365
AttributeError: 'str' object has no attribute 'to_datetime'

2025-05-13 22:59:23,230 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f57de0b2sm17596530f8f.19 - gsmtp')
2025-05-13 22:59:23,232 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-13 22:59:23,264 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\22\loans.parquet
2025-05-13 22:59:23,264 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\22\loans.parquet
2025-05-13 22:59:23,264 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\22\loans.parquet
2025-05-13 22:59:23,268 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: unsupported operand type(s) for -: 'str' and 'str'
Traceback (most recent call last):
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 218, in _na_arithmetic_op
    result = func(left, right)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\roperator.py", line 15, in rsub
    return right - left
TypeError: unsupported operand type(s) for -: 'str' and 'str'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\loans_transformer.py", line 19, in transform
    df['age'] = (self.partition_date - df['utilization_date']).dt.days
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\common.py", line 76, in new_method
    return method(self, other)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\arraylike.py", line 198, in __rsub__
    return self._arith_method(other, roperator.rsub)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\series.py", line 6135, in _arith_method
    return base.IndexOpsMixin._arith_method(self, other, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\base.py", line 1382, in _arith_method
    result = ops.arithmetic_op(lvalues, rvalues, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 283, in arithmetic_op
    res_values = _na_arithmetic_op(left, right, op)  # type: ignore[arg-type]
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 227, in _na_arithmetic_op
    result = _masked_arith_op(left, right, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 182, in _masked_arith_op
    result[mask] = op(xrav[mask], y)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\roperator.py", line 15, in rsub
    return right - left
TypeError: unsupported operand type(s) for -: 'str' and 'str'

2025-05-13 22:59:24,776 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f5a4bbf0sm17042300f8f.82 - gsmtp')
2025-05-13 22:59:24,777 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-13 22:59:24,842 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\22\support_tickets.parquet
2025-05-13 22:59:24,842 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\22\support_tickets.parquet
2025-05-13 22:59:24,842 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\22\support_tickets.parquet
2025-05-13 22:59:24,842 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\22\support_tickets.parquet
2025-05-13 22:59:24,851 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: 'issue_date'
Traceback (most recent call last):
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\indexes\base.py", line 3805, in get_loc
    return self._engine.get_loc(casted_key)
  File "index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas\\_libs\\hashtable_class_helper.pxi", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas\\_libs\\hashtable_class_helper.pxi", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'issue_date'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\support_tickets_transformer.py", line 16, in transform
    df['age'] = (self.partition_date - df['issue_date']).dt.days
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\frame.py", line 4102, in __getitem__
    indexer = self.columns.get_loc(key)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\indexes\base.py", line 3812, in get_loc
    raise KeyError(key) from err
KeyError: 'issue_date'

2025-05-13 22:59:26,370 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f58f2fc4sm17534021f8f.56 - gsmtp')
2025-05-13 22:59:26,372 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-13 22:59:26,831 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\22\transactions.parquet
2025-05-13 22:59:26,831 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\22\transactions.parquet
2025-05-13 22:59:26,831 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\22\transactions.parquet
2025-05-13 22:59:26,831 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\22\transactions.parquet
2025-05-13 22:59:26,831 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\22\transactions.parquet
2025-05-13 22:59:26,940 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\22\transactions.parquet
2025-05-13 22:59:26,940 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\22\transactions.parquet
2025-05-13 22:59:26,940 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\22\transactions.parquet
2025-05-13 22:59:26,940 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\22\transactions.parquet
2025-05-13 22:59:26,940 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\22\transactions.parquet
2025-05-13 22:59:26,940 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\22\transactions.parquet
2025-05-13 22:59:26,999 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\22\transactions /data/2025-05-13/22/transactions.parquet' returned non-zero exit status 1.
2025-05-13 22:59:26,999 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\22\transactions /data/2025-05-13/22/transactions.parquet' returned non-zero exit status 1.
2025-05-13 22:59:26,999 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\22\transactions /data/2025-05-13/22/transactions.parquet' returned non-zero exit status 1.
2025-05-13 22:59:26,999 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\22\transactions /data/2025-05-13/22/transactions.parquet' returned non-zero exit status 1.
2025-05-13 22:59:26,999 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\22\transactions /data/2025-05-13/22/transactions.parquet' returned non-zero exit status 1.
2025-05-13 22:59:26,999 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\22\transactions /data/2025-05-13/22/transactions.parquet' returned non-zero exit status 1.
2025-05-13 22:59:27,008 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\22\transactions /data/2025-05-13/22/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\22\transactions /data/2025-05-13/22/transactions.parquet' returned non-zero exit status 1.

2025-05-13 22:59:28,424 - __main__ - INFO - Pipeline stopped by user
2025-05-13 23:05:53,645 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-13 23:05:53,649 - __main__ - INFO - Pipeline initialized successfully
2025-05-13 23:05:53,651 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-13 23:05:53,651 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-13 23:05:54,165 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:05:54,257 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: cannot subtract DatetimeArray from ndarray
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\credit_cards_billing_transformer.py", line 22, in transform
    df['late_days'] = (df['payment_date'] - df['due_date']).dt.days
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\common.py", line 76, in new_method
    return method(self, other)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\arraylike.py", line 194, in __sub__
    return self._arith_method(other, operator.sub)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\series.py", line 6135, in _arith_method
    return base.IndexOpsMixin._arith_method(self, other, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\base.py", line 1382, in _arith_method
    result = ops.arithmetic_op(lvalues, rvalues, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 273, in arithmetic_op
    res_values = op(left, right)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\arrays\datetimelike.py", line 2200, in __array_ufunc__
    return super().__array_ufunc__(ufunc, method, *inputs, **kwargs)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\arrays\base.py", line 2282, in __array_ufunc__
    result = arraylike.maybe_dispatch_ufunc_to_dunder_op(
  File "ops_dispatch.pyx", line 113, in pandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\arrays\datetimelike.py", line 1499, in __rsub__
    raise TypeError(
TypeError: cannot subtract DatetimeArray from ndarray

2025-05-13 23:05:55,841 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f5a2ca31sm17435540f8f.65 - gsmtp')
2025-05-13 23:05:55,844 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-13 23:05:56,294 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:05:56,294 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:05:56,298 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: 'str' object has no attribute 'to_datetime'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\customer_profile_transformer.py", line 17, in transform
    df['tenure'] = (self.partition_date.to_datetime() - df['account_open_date'].to_datetime()   ).dt.days // 365
AttributeError: 'str' object has no attribute 'to_datetime'

2025-05-13 23:05:57,855 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442ebd47d39sm25808615e9.1 - gsmtp')
2025-05-13 23:05:57,856 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-13 23:05:57,889 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:05:57,889 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:05:57,889 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:05:57,892 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: 'str' object has no attribute 'to_datetime'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\loans_transformer.py", line 19, in transform
    df['age'] = (self.partition_date.to_datetime() - df['utilization_date'].to_datetime()).dt.days
AttributeError: 'str' object has no attribute 'to_datetime'

2025-05-13 23:05:59,374 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f57ddd2dsm17284238f8f.9 - gsmtp')
2025-05-13 23:05:59,375 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-13 23:05:59,505 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:05:59,505 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:05:59,505 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:05:59,505 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:05:59,509 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: 'str' object has no attribute 'to_datetime'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\support_tickets_transformer.py", line 16, in transform
    df['age'] = (self.partition_date.to_datetime() - df['issue_date'].to_datetime()).dt.days
AttributeError: 'str' object has no attribute 'to_datetime'

2025-05-13 23:06:01,051 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442cd3aeca5sm229421105e9.26 - gsmtp')
2025-05-13 23:06:01,053 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-13 23:06:01,530 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:06:01,530 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:06:01,530 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:06:01,530 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:06:01,530 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:06:01,750 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:06:01,750 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:06:01,750 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:06:01,750 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:06:01,750 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:06:01,750 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:06:01,801 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:06:01,801 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:06:01,801 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:06:01,801 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:06:01,801 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:06:01,801 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:06:01,807 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.

2025-05-13 23:06:03,355 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f5a2ce36sm17552919f8f.71 - gsmtp')
2025-05-13 23:06:06,524 - __main__ - INFO - Pipeline stopped by user
--------------------------------------------

2025-05-13 23:11:13,478 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-13 23:11:13,481 - __main__ - INFO - Pipeline initialized successfully
2025-05-13 23:11:13,482 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-13 23:11:13,484 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-13 23:11:14,119 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:11:14,216 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: cannot subtract DatetimeArray from ndarray
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\credit_cards_billing_transformer.py", line 23, in transform
    df['late_days'] = (df['payment_date'] - df['due_date']).dt.days
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\common.py", line 76, in new_method
    return method(self, other)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\arraylike.py", line 194, in __sub__
    return self._arith_method(other, operator.sub)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\series.py", line 6135, in _arith_method
    return base.IndexOpsMixin._arith_method(self, other, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\base.py", line 1382, in _arith_method
    result = ops.arithmetic_op(lvalues, rvalues, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 273, in arithmetic_op
    res_values = op(left, right)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\arrays\datetimelike.py", line 2200, in __array_ufunc__
    return super().__array_ufunc__(ufunc, method, *inputs, **kwargs)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\arrays\base.py", line 2282, in __array_ufunc__
    result = arraylike.maybe_dispatch_ufunc_to_dunder_op(
  File "ops_dispatch.pyx", line 113, in pandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\arrays\datetimelike.py", line 1499, in __rsub__
    raise TypeError(
TypeError: cannot subtract DatetimeArray from ndarray

2025-05-13 23:11:16,930 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f58f396asm17667463f8f.59 - gsmtp')
2025-05-13 23:11:16,931 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-13 23:11:17,394 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:11:17,394 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:11:17,395 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: 'str' object has no attribute 'to_datetime'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\customer_profile_transformer.py", line 17, in transform
    df['tenure'] = (self.partition_date.to_datetime() - df['account_open_date'].to_datetime()   ).dt.days // 365
AttributeError: 'str' object has no attribute 'to_datetime'

2025-05-13 23:11:19,439 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f58eca4asm17111692f8f.24 - gsmtp')
2025-05-13 23:11:19,440 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-13 23:11:19,514 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:11:19,514 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:11:19,514 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:11:19,517 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: 'str' object has no attribute 'to_datetime'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\loans_transformer.py", line 19, in transform
    df['age'] = (self.partition_date.to_datetime() - df['utilization_date'].to_datetime()).dt.days
AttributeError: 'str' object has no attribute 'to_datetime'

2025-05-13 23:11:21,755 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f5a4c78fsm17443799f8f.97 - gsmtp')
2025-05-13 23:11:21,756 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-13 23:11:21,818 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:11:21,818 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:11:21,818 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:11:21,818 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:11:21,821 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: 'str' object has no attribute 'to_datetime'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\support_tickets_transformer.py", line 16, in transform
    df['age'] = (self.partition_date.to_datetime() - df['issue_date'].to_datetime()).dt.days
AttributeError: 'str' object has no attribute 'to_datetime'

2025-05-13 23:11:23,677 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442d687ae5asm178230915e9.36 - gsmtp')
2025-05-13 23:11:23,679 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-13 23:11:24,102 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:11:24,102 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:11:24,102 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:11:24,102 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:11:24,102 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:11:24,207 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:11:24,207 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:11:24,207 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:11:24,207 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:11:24,207 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:11:24,207 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:11:24,260 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:11:24,260 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:11:24,260 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:11:24,260 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:11:24,260 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:11:24,260 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:11:24,269 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.

2025-05-13 23:11:26,859 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f57ddfc9sm17143412f8f.5 - gsmtp')
2025-05-13 23:11:28,491 - __main__ - INFO - Pipeline stopped by user
2025-05-13 23:26:19,833 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-13 23:26:19,835 - __main__ - INFO - Pipeline initialized successfully
2025-05-13 23:26:19,836 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-13 23:26:19,836 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-13 23:26:20,362 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:26:20,689 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:26:20,689 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:26:20,739 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:26:20,739 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:26:20,743 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.

2025-05-13 23:26:22,338 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442f338050csm467205e9.10 - gsmtp')
2025-05-13 23:26:22,339 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-13 23:26:22,920 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:26:22,920 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:26:22,920 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:26:23,388 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:26:23,388 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:26:23,388 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:26:23,388 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:26:23,440 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:26:23,440 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:26:23,440 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:26:23,440 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:26:23,444 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.

2025-05-13 23:26:24,971 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442ebd47d39sm26098075e9.1 - gsmtp')
2025-05-13 23:26:24,973 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-13 23:26:24,992 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:26:24,992 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:26:24,992 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:26:24,992 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:26:24,992 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:26:24,996 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: 'str' object has no attribute 'to_datetime'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\loans_transformer.py", line 19, in transform
    df['age'] = (self.partition_date.to_datetime() - df['utilization_date'].to_datetime()).dt.days
AttributeError: 'str' object has no attribute 'to_datetime'

2025-05-13 23:26:26,647 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f58eb9dfsm17584341f8f.31 - gsmtp')
2025-05-13 23:26:26,649 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-13 23:26:26,701 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:26:26,701 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:26:26,701 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:26:26,701 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:26:26,701 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:26:26,701 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:26:26,706 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: 'str' object has no attribute 'to_datetime'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\support_tickets_transformer.py", line 16, in transform
    df['age'] = (self.partition_date.to_datetime() - df['issue_date'].to_datetime()).dt.days
AttributeError: 'str' object has no attribute 'to_datetime'

2025-05-13 23:26:28,278 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442f3951adcsm369475e9.19 - gsmtp')
2025-05-13 23:26:28,280 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-13 23:26:28,804 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:26:28,804 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:26:28,804 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:26:28,804 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:26:28,804 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:26:28,804 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:26:28,804 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:26:28,902 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:26:28,902 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:26:28,902 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:26:28,902 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:26:28,902 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:26:28,902 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:26:28,902 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:26:28,902 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:26:28,951 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:26:28,951 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:26:28,951 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:26:28,951 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:26:28,951 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:26:28,951 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:26:28,951 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:26:28,951 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:26:28,957 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.

2025-05-13 23:26:30,512 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f58ecb46sm17535361f8f.30 - gsmtp')
2025-05-13 23:26:32,317 - __main__ - INFO - Pipeline stopped by user
2025-05-13 23:28:44,163 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-13 23:28:44,166 - __main__ - INFO - Pipeline initialized successfully
2025-05-13 23:28:44,167 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-13 23:28:44,168 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-13 23:28:44,755 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:28:45,085 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:28:45,085 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:28:45,134 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:28:45,134 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:28:45,137 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.

2025-05-13 23:28:47,289 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442ebda7d2csm22098075e9.3 - gsmtp')
2025-05-13 23:28:47,290 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-13 23:28:47,727 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:28:47,727 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:28:47,727 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:28:48,006 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:28:48,006 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:28:48,006 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:28:48,006 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:28:48,057 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:28:48,057 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:28:48,057 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:28:48,057 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:28:48,061 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.

2025-05-13 23:28:49,716 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f57dde6bsm17611680f8f.13 - gsmtp')
2025-05-13 23:28:49,718 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-13 23:28:49,737 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:28:49,737 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:28:49,737 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:28:49,737 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:28:49,737 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:28:49,749 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: unsupported operand type(s) for -: 'str' and 'str'
Traceback (most recent call last):
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 218, in _na_arithmetic_op
    result = func(left, right)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\roperator.py", line 15, in rsub
    return right - left
TypeError: unsupported operand type(s) for -: 'str' and 'str'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\loans_transformer.py", line 21, in transform
    df['total_cost'] = self._calculate_total_cost(df['amount_utilized'], df['utilization_date'])
  File "d:\ITI\Python\Project\src\transformers\loans_transformer.py", line 27, in _calculate_total_cost
    years = math.ceil((self.partition_date - utilization_date).days / 365)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\common.py", line 76, in new_method
    return method(self, other)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\arraylike.py", line 198, in __rsub__
    return self._arith_method(other, roperator.rsub)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\series.py", line 6135, in _arith_method
    return base.IndexOpsMixin._arith_method(self, other, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\base.py", line 1382, in _arith_method
    result = ops.arithmetic_op(lvalues, rvalues, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 283, in arithmetic_op
    res_values = _na_arithmetic_op(left, right, op)  # type: ignore[arg-type]
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 227, in _na_arithmetic_op
    result = _masked_arith_op(left, right, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 182, in _masked_arith_op
    result[mask] = op(xrav[mask], y)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\roperator.py", line 15, in rsub
    return right - left
TypeError: unsupported operand type(s) for -: 'str' and 'str'

2025-05-13 23:28:52,132 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442eb8c92d9sm22498115e9.2 - gsmtp')
2025-05-13 23:28:52,133 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-13 23:28:52,271 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:28:52,271 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:28:52,271 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:28:52,271 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:28:52,271 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:28:52,271 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:28:52,275 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: 'str' object has no attribute 'to_datetime'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\support_tickets_transformer.py", line 16, in transform
    df['age'] = (self.partition_date.to_datetime() - df['issue_date'].to_datetime()).dt.days
AttributeError: 'str' object has no attribute 'to_datetime'

2025-05-13 23:28:53,964 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442f39ef400sm149165e9.33 - gsmtp')
2025-05-13 23:28:53,965 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-13 23:28:54,590 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:28:54,590 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:28:54,590 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:28:54,590 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:28:54,590 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:28:54,590 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:28:54,590 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:28:54,715 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:28:54,715 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:28:54,715 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:28:54,715 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:28:54,715 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:28:54,715 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:28:54,715 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:28:54,715 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:28:54,766 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:28:54,766 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:28:54,766 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:28:54,766 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:28:54,766 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:28:54,766 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:28:54,766 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:28:54,766 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:28:54,771 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.

2025-05-13 23:28:56,228 - __main__ - INFO - Pipeline stopped by user
2025-05-13 23:34:04,138 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-13 23:34:04,142 - __main__ - INFO - Pipeline initialized successfully
2025-05-13 23:34:04,143 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-13 23:34:21,838 - __main__ - INFO - Pipeline stopped by user
2025-05-13 23:35:04,890 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-13 23:35:04,893 - __main__ - INFO - Pipeline initialized successfully
2025-05-13 23:35:04,893 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-13 23:35:04,894 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-13 23:35:05,467 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:35:05,780 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:35:05,780 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:35:05,831 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:35:05,831 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:35:05,835 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.

2025-05-13 23:35:07,446 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f5a4cc44sm17088829f8f.85 - gsmtp')
2025-05-13 23:35:07,449 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-13 23:35:07,890 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:35:07,890 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:35:07,890 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:35:08,197 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:35:08,197 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:35:08,197 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:35:08,197 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:35:08,253 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:35:08,253 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:35:08,253 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:35:08,253 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:35:08,257 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.

2025-05-13 23:35:09,756 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f57ddfbesm17663496f8f.10 - gsmtp')
2025-05-13 23:35:09,757 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-13 23:35:09,776 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:35:09,776 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:35:09,776 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:35:09,776 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:35:09,776 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:35:09,790 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: unsupported operand type(s) for -: 'Timestamp' and 'str'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\loans_transformer.py", line 21, in transform
    df['total_cost'] = self._calculate_total_cost(df['amount_utilized'], df['utilization_date'])
  File "d:\ITI\Python\Project\src\transformers\loans_transformer.py", line 28, in _calculate_total_cost
    years = math.ceil((partition_date - utilization_date).days / 365)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\common.py", line 76, in new_method
    return method(self, other)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\arraylike.py", line 198, in __rsub__
    return self._arith_method(other, roperator.rsub)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\series.py", line 6135, in _arith_method
    return base.IndexOpsMixin._arith_method(self, other, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\base.py", line 1382, in _arith_method
    result = ops.arithmetic_op(lvalues, rvalues, op)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\ops\array_ops.py", line 273, in arithmetic_op
    res_values = op(left, right)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\roperator.py", line 15, in rsub
    return right - left
TypeError: unsupported operand type(s) for -: 'Timestamp' and 'str'

2025-05-13 23:35:11,331 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442f337db8asm706435e9.9 - gsmtp')
2025-05-13 23:35:11,333 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-13 23:35:11,391 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:35:11,391 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:35:11,391 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:35:11,391 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:35:11,391 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:35:11,391 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:35:11,405 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: 'issue_date'
Traceback (most recent call last):
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\indexes\base.py", line 3805, in get_loc
    return self._engine.get_loc(casted_key)
  File "index.pyx", line 167, in pandas._libs.index.IndexEngine.get_loc
  File "index.pyx", line 196, in pandas._libs.index.IndexEngine.get_loc
  File "pandas\\_libs\\hashtable_class_helper.pxi", line 7081, in pandas._libs.hashtable.PyObjectHashTable.get_item
  File "pandas\\_libs\\hashtable_class_helper.pxi", line 7089, in pandas._libs.hashtable.PyObjectHashTable.get_item
KeyError: 'issue_date'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\support_tickets_transformer.py", line 17, in transform
    df['age'] = (partition_date - pd.to_datetime(df['issue_date'])).dt.days
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\frame.py", line 4102, in __getitem__
    indexer = self.columns.get_loc(key)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\indexes\base.py", line 3812, in get_loc
    raise KeyError(key) from err
KeyError: 'issue_date'

2025-05-13 23:35:13,203 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f57de001sm17138362f8f.20 - gsmtp')
2025-05-13 23:35:13,205 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-13 23:35:13,679 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:35:13,679 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:35:13,679 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:35:13,679 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:35:13,679 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:35:13,679 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:35:13,679 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:35:13,782 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:35:13,782 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:35:13,782 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:35:13,782 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:35:13,782 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:35:13,782 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:35:13,782 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:35:13,782 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:35:13,842 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:35:13,842 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:35:13,842 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:35:13,842 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:35:13,842 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:35:13,842 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:35:13,842 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:35:13,842 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:35:13,850 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.

2025-05-13 23:35:15,440 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f58ed0a5sm17155670f8f.21 - gsmtp')
2025-05-13 23:35:20,545 - __main__ - INFO - Pipeline stopped by user
2025-05-13 23:41:33,404 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-13 23:41:33,408 - __main__ - INFO - Pipeline initialized successfully
2025-05-13 23:41:33,408 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-13 23:41:33,409 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-13 23:41:34,182 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:41:34,727 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:41:34,727 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:41:34,794 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:41:34,794 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:41:34,797 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.

2025-05-13 23:41:36,369 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f5a2ca47sm17506250f8f.73 - gsmtp')
2025-05-13 23:41:36,370 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-13 23:41:37,425 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:41:37,425 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:41:37,425 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:41:37,690 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:41:37,690 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:41:37,690 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:41:37,690 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:41:37,739 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:41:37,739 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:41:37,739 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:41:37,739 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:41:37,744 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.

2025-05-13 23:41:39,239 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f58f2a79sm17157047f8f.48 - gsmtp')
2025-05-13 23:41:39,241 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-13 23:41:39,323 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:41:39,323 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:41:39,323 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:41:39,323 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:41:39,323 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:41:39,333 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: 'Series' object has no attribute 'days'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\loans_transformer.py", line 21, in transform
    df['total_cost'] = self._calculate_total_cost(df['amount_utilized'], pd.to_datetime(df['utilization_date']))
  File "d:\ITI\Python\Project\src\transformers\loans_transformer.py", line 28, in _calculate_total_cost
    years = math.ceil((partition_date - utilization_date).days / 365)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\generic.py", line 6299, in __getattr__
    return object.__getattribute__(self, name)
AttributeError: 'Series' object has no attribute 'days'

2025-05-13 23:41:41,939 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f5a4c804sm17639846f8f.95 - gsmtp')
2025-05-13 23:41:41,940 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-13 23:41:42,111 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:41:42,111 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:41:42,111 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:41:42,111 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:41:42,111 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:41:42,111 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:41:42,165 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:41:42,165 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:41:42,165 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:41:42,165 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:41:42,165 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:41:42,165 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:41:42,165 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:41:42,220 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:41:42,220 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:41:42,220 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:41:42,220 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:41:42,220 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:41:42,220 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:41:42,220 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:41:42,226 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.

2025-05-13 23:41:43,978 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442f3368d1csm939645e9.8 - gsmtp')
2025-05-13 23:41:43,982 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-13 23:41:44,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:41:44,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:41:44,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:41:44,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:41:44,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:41:44,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:41:44,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:41:44,694 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:41:44,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:41:44,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:41:44,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:41:44,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:41:44,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:41:44,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:41:44,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:41:44,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:41:44,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:41:44,860 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:41:44,860 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:41:44,860 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:41:44,860 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:41:44,860 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:41:44,860 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:41:44,860 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:41:44,860 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:41:44,860 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:41:44,866 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.

2025-05-13 23:41:46,770 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f57dde27sm17785026f8f.17 - gsmtp')
2025-05-13 23:44:16,818 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-13 23:44:17,381 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,381 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,381 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,381 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,381 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,381 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,381 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,381 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,381 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,381 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,729 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,729 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,729 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,729 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,729 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,729 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,729 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,729 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,729 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,729 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,729 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:44:17,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:44:17,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:44:17,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:44:17,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:44:17,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:44:17,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:44:17,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:44:17,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:44:17,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:44:17,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:44:17,786 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:44:17,795 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.

2025-05-13 23:44:19,495 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f57de001sm17156959f8f.20 - gsmtp')
2025-05-13 23:44:19,498 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-13 23:44:19,898 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:19,898 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:19,898 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:19,898 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:19,898 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:19,898 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:19,898 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:19,898 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:19,898 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:19,898 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:19,898 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:19,898 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:20,200 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:20,200 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:20,200 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:20,200 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:20,200 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:20,200 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:20,200 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:20,200 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:20,200 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:20,200 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:20,200 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:20,200 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:20,200 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:44:20,261 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:44:20,261 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:44:20,261 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:44:20,261 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:44:20,261 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:44:20,261 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:44:20,261 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:44:20,261 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:44:20,261 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:44:20,261 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:44:20,261 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:44:20,261 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:44:20,261 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:44:20,274 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.

2025-05-13 23:44:21,992 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442f3951b6dsm850295e9.17 - gsmtp')
2025-05-13 23:44:21,994 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-13 23:44:22,011 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:44:22,011 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:44:22,011 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:44:22,011 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:44:22,011 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:44:22,011 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:44:22,011 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:44:22,011 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:44:22,011 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:44:22,011 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:44:22,011 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:44:22,011 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:44:22,011 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:44:22,011 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:44:22,078 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: 'Series' object has no attribute 'days'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\loans_transformer.py", line 21, in transform
    df['total_cost'] = self._calculate_total_cost(df['amount_utilized'], pd.to_datetime(df['utilization_date']))
  File "d:\ITI\Python\Project\src\transformers\loans_transformer.py", line 28, in _calculate_total_cost
    years = math.ceil((partition_date - utilization_date).dt.days / 365)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\generic.py", line 6299, in __getattr__
    return object.__getattribute__(self, name)
AttributeError: 'Series' object has no attribute 'days'

2025-05-13 23:44:27,905 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442f39e8545sm573795e9.31 - gsmtp')
2025-05-13 23:44:27,907 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-13 23:44:27,975 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:27,975 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:27,975 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:27,975 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:27,975 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:27,975 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:27,975 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:27,975 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:27,975 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:27,975 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:27,975 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:27,975 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:27,975 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:27,975 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:27,975 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:28,016 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:28,016 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:28,016 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:28,016 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:28,016 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:28,016 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:28,016 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:28,016 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:28,016 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:28,016 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:28,016 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:28,016 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:28,016 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:28,016 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:28,016 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:28,016 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:44:28,078 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:44:28,078 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:44:28,078 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:44:28,078 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:44:28,078 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:44:28,078 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:44:28,078 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:44:28,078 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:44:28,078 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:44:28,078 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:44:28,078 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:44:28,078 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:44:28,078 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:44:28,078 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:44:28,078 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:44:28,078 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:44:28,091 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.

2025-05-13 23:44:30,376 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442f337db0dsm935585e9.13 - gsmtp')
2025-05-13 23:44:30,378 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-13 23:44:30,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,948 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,948 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,948 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,948 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,948 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,948 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,948 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,948 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,948 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,948 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,948 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,948 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,948 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,948 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,948 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,948 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,948 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:44:30,948 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:44:31,006 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:44:31,006 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:44:31,006 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:44:31,006 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:44:31,006 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:44:31,006 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:44:31,006 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:44:31,006 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:44:31,006 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:44:31,006 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:44:31,006 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:44:31,006 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:44:31,006 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:44:31,006 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:44:31,006 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:44:31,006 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:44:31,006 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:44:31,006 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:44:31,016 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.

2025-05-13 23:44:32,544 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f58ecaeasm17226153f8f.28 - gsmtp')
2025-05-13 23:45:42,534 - __main__ - INFO - Pipeline stopped by user
2025-05-13 23:46:18,620 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-13 23:46:18,622 - __main__ - INFO - Pipeline initialized successfully
2025-05-13 23:46:18,623 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-13 23:46:18,624 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-13 23:46:19,172 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:46:19,470 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:46:19,470 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:46:19,522 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:46:19,522 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:46:19,525 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.

2025-05-13 23:46:21,465 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442f39e84d3sm631435e9.32 - gsmtp')
2025-05-13 23:46:21,466 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-13 23:46:21,931 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:46:21,931 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:46:21,931 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:46:22,200 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:46:22,200 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:46:22,200 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:46:22,200 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:46:22,253 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:46:22,253 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:46:22,253 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:46:22,253 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:46:22,257 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.

2025-05-13 23:46:24,054 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f58f28f7sm17204395f8f.41 - gsmtp')
2025-05-13 23:46:24,055 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-13 23:46:24,069 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:46:24,069 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:46:24,069 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:46:24,069 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:46:24,069 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:46:24,087 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: cannot convert the series to <class 'float'>
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\loans_transformer.py", line 21, in transform
    df['total_cost'] = self._calculate_total_cost(df['amount_utilized'], pd.to_datetime(df['utilization_date']))
  File "d:\ITI\Python\Project\src\transformers\loans_transformer.py", line 28, in _calculate_total_cost
    years = math.ceil((partition_date - utilization_date).dt.days / 365)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\site-packages\pandas\core\series.py", line 248, in wrapper
    raise TypeError(f"cannot convert the series to {converter}")
TypeError: cannot convert the series to <class 'float'>

2025-05-13 23:46:25,795 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f5a2cf0esm17473266f8f.79 - gsmtp')
2025-05-13 23:46:25,797 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-13 23:46:25,878 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:46:25,878 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:46:25,878 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:46:25,878 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:46:25,878 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:46:25,878 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:46:25,926 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:46:25,926 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:46:25,926 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:46:25,926 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:46:25,926 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:46:25,926 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:46:25,926 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:46:25,982 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:46:25,982 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:46:25,982 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:46:25,982 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:46:25,982 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:46:25,982 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:46:25,982 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:46:25,988 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.

2025-05-13 23:46:27,477 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f57ddde0sm17750258f8f.14 - gsmtp')
2025-05-13 23:46:27,480 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-13 23:46:28,061 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:46:28,061 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:46:28,061 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:46:28,061 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:46:28,061 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:46:28,061 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:46:28,061 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:46:28,061 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:46:28,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:46:28,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:46:28,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:46:28,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:46:28,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:46:28,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:46:28,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:46:28,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:46:28,174 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:46:28,233 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:46:28,233 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:46:28,233 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:46:28,233 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:46:28,233 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:46:28,233 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:46:28,233 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:46:28,233 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:46:28,233 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:46:28,242 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.

2025-05-13 23:46:31,801 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f57ddd53sm17356902f8f.1 - gsmtp')
2025-05-13 23:46:49,799 - __main__ - INFO - Pipeline stopped by user
2025-05-13 23:49:54,261 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-13 23:49:54,266 - __main__ - INFO - Pipeline initialized successfully
2025-05-13 23:49:54,267 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-13 23:49:54,268 - src.pipeline.main_pipeline - INFO - Started processing credit_cards_billing.csv
2025-05-13 23:49:54,893 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/extracted\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:49:55,216 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:49:55,216 - src.writers.base_writer - INFO - Successfully wrote 200000 rows to checkpoint/transformed\2025-05-13\23\credit_cards_billing.parquet
2025-05-13 23:49:55,263 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:49:55,263 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
2025-05-13 23:49:55,268 - src.utils.error_handler - ERROR - Error in Processing file credit_cards_billing.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\credit_cards_billing /data/2025-05-13/23/credit_cards_billing.parquet' returned non-zero exit status 1.

2025-05-13 23:49:57,203 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f58eca4asm17196352f8f.24 - gsmtp')
2025-05-13 23:49:57,205 - src.pipeline.main_pipeline - INFO - Started processing customer_profiles.csv
2025-05-13 23:49:57,730 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:49:57,730 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:49:57,730 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:49:58,120 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:49:58,120 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:49:58,120 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:49:58,120 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\customer_profiles.parquet
2025-05-13 23:49:58,170 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:49:58,170 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:49:58,170 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:49:58,170 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
2025-05-13 23:49:58,175 - src.utils.error_handler - ERROR - Error in Processing file customer_profiles.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\customer_profiles /data/2025-05-13/23/customer_profiles.parquet' returned non-zero exit status 1.

2025-05-13 23:49:59,723 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials 5b1f17b1804b1-442f3979275sm909255e9.34 - gsmtp')
2025-05-13 23:49:59,725 - src.pipeline.main_pipeline - INFO - Started processing loans.txt
2025-05-13 23:49:59,743 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:49:59,743 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:49:59,743 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:49:59,743 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:49:59,743 - src.writers.base_writer - INFO - Successfully wrote 1000 rows to checkpoint/extracted\2025-05-13\23\loans.parquet
2025-05-13 23:49:59,755 - src.utils.error_handler - ERROR - Error in Processing file loans.txt: encrypt() missing 2 required positional arguments: 'text' and 'file_name'
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 158, in _process_file
    df = transformer.transform(df)
  File "d:\ITI\Python\Project\src\transformers\loans_transformer.py", line 22, in transform
    df['loan_reason'] = Encryptor.encrypt(df['loan_reason'])
TypeError: encrypt() missing 2 required positional arguments: 'text' and 'file_name'

2025-05-13 23:50:01,479 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f5a4c5c5sm17705706f8f.96 - gsmtp')
2025-05-13 23:50:01,481 - src.pipeline.main_pipeline - INFO - Started processing support_tickets.csv
2025-05-13 23:50:01,535 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:50:01,535 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:50:01,535 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:50:01,535 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:50:01,535 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:50:01,535 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/extracted\2025-05-13\23\support_tickets.parquet
2025-05-13 23:50:01,580 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:50:01,580 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:50:01,580 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:50:01,580 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:50:01,580 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:50:01,580 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:50:01,580 - src.writers.base_writer - INFO - Successfully wrote 15000 rows to checkpoint/transformed\2025-05-13\23\support_tickets.parquet
2025-05-13 23:50:01,637 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:50:01,637 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:50:01,637 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:50:01,637 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:50:01,637 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:50:01,637 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:50:01,637 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
2025-05-13 23:50:01,646 - src.utils.error_handler - ERROR - Error in Processing file support_tickets.csv: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\support_tickets /data/2025-05-13/23/support_tickets.parquet' returned non-zero exit status 1.

2025-05-13 23:50:03,269 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f58eca4asm17196555f8f.24 - gsmtp')
2025-05-13 23:50:03,271 - src.pipeline.main_pipeline - INFO - Started processing transactions.json
2025-05-13 23:50:03,698 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:50:03,698 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:50:03,698 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:50:03,698 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:50:03,698 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:50:03,698 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:50:03,698 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:50:03,698 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/extracted\2025-05-13\23\transactions.parquet
2025-05-13 23:50:03,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:50:03,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:50:03,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:50:03,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:50:03,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:50:03,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:50:03,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:50:03,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:50:03,811 - src.writers.base_writer - INFO - Successfully wrote 100000 rows to checkpoint/transformed\2025-05-13\23\transactions.parquet
2025-05-13 23:50:03,929 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:50:03,929 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:50:03,929 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:50:03,929 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:50:03,929 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:50:03,929 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:50:03,929 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:50:03,929 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:50:03,929 - src.writers.base_writer - ERROR - Failed to upload to HDFS: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
2025-05-13 23:50:03,962 - src.utils.error_handler - ERROR - Error in Processing file transactions.json: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.
Traceback (most recent call last):
  File "d:\ITI\Python\Project\src\pipeline\main_pipeline.py", line 169, in _process_file
    transformed_writer.upload_to_hdfs(transformed_path, hdfs_path)
  File "d:\ITI\Python\Project\src\writers\base_writer.py", line 23, in upload_to_hdfs
    subprocess.run(command, shell=True, check=True)
  File "C:\Users\randa\AppData\Local\Programs\Python\Python39\lib\subprocess.py", line 528, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'hadoop fs -put -f checkpoint/transformed\2025-05-13\23\transactions /data/2025-05-13/23/transactions.parquet' returned non-zero exit status 1.

2025-05-13 23:50:05,720 - src.utils.error_handler - ERROR - Failed to send error notification email: (535, b'5.7.8 Username and Password not accepted. For more information, go to\n5.7.8  https://support.google.com/mail/?p=BadCredentials ffacd0b85a97d-3a1f5a4c5a4sm17342690f8f.81 - gsmtp')
2025-05-13 23:50:21,991 - __main__ - INFO - Pipeline stopped by user
2025-05-13 23:56:00,656 - __main__ - INFO - Starting NexaBank Data Pipeline
2025-05-13 23:56:00,659 - __main__ - INFO - Pipeline initialized successfully
2025-05-13 23:56:00,659 - src.pipeline.main_pipeline - INFO - Starting pipeline execution
2025-05-13 23:56:03,811 - __main__ - INFO - Pipeline stopped by user
=========================================



